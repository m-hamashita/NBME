{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:48:29.183757Z",
     "iopub.status.busy": "2022-05-03T03:48:29.182927Z",
     "iopub.status.idle": "2022-05-03T03:48:29.215920Z",
     "shell.execute_reply": "2022-05-03T03:48:29.216572Z",
     "shell.execute_reply.started": "2022-05-03T02:40:27.158937Z"
    },
    "papermill": {
     "duration": 0.07299,
     "end_time": "2022-05-03T03:48:29.216882",
     "exception": false,
     "start_time": "2022-05-03T03:48:29.143892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "transformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n",
    "\n",
    "input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "if conversion_path.exists():\n",
    "    conversion_path.unlink()\n",
    "\n",
    "shutil.copy(convert_file, transformers_path)\n",
    "deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py']:\n",
    "    if str(filename).startswith(\"deberta\"):\n",
    "        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n",
    "    else:\n",
    "        filepath = deberta_v2_path/filename\n",
    "    if filepath.exists():\n",
    "        filepath.unlink()\n",
    "\n",
    "    shutil.copy(input_dir/filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:48:29.274811Z",
     "iopub.status.busy": "2022-05-03T03:48:29.274053Z",
     "iopub.status.idle": "2022-05-03T03:48:38.284506Z",
     "shell.execute_reply": "2022-05-03T03:48:38.283934Z",
     "shell.execute_reply.started": "2022-05-03T02:40:38.394733Z"
    },
    "papermill": {
     "duration": 9.040771,
     "end_time": "2022-05-03T03:48:38.284663",
     "exception": false,
     "start_time": "2022-05-03T03:48:29.243892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import (\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:48:38.355605Z",
     "iopub.status.busy": "2022-05-03T03:48:38.350432Z",
     "iopub.status.idle": "2022-05-03T03:48:38.361602Z",
     "shell.execute_reply": "2022-05-03T03:48:38.362398Z",
     "shell.execute_reply.started": "2022-05-03T02:40:45.564468Z"
    },
    "papermill": {
     "duration": 0.045622,
     "end_time": "2022-05-03T03:48:38.362644",
     "exception": false,
     "start_time": "2022-05-03T03:48:38.317022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_logger(filename=\"inference\"):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026668,
     "end_time": "2022-05-03T03:48:38.418813",
     "exception": false,
     "start_time": "2022-05-03T03:48:38.392145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4種のモデルの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025994,
     "end_time": "2022-05-03T03:48:38.474971",
     "exception": false,
     "start_time": "2022-05-03T03:48:38.448977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## exp099 deberta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:48:38.531114Z",
     "iopub.status.busy": "2022-05-03T03:48:38.530107Z",
     "iopub.status.idle": "2022-05-03T03:48:38.548182Z",
     "shell.execute_reply": "2022-05-03T03:48:38.547618Z",
     "shell.execute_reply.started": "2022-05-03T02:40:45.579360Z"
    },
    "papermill": {
     "duration": 0.047164,
     "end_time": "2022-05-03T03:48:38.548372",
     "exception": false,
     "start_time": "2022-05-03T03:48:38.501208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp099_oof_char_prob():\n",
    "    from transformers.models.deberta_v2.tokenization_deberta_v2_fast import (\n",
    "        DebertaV2TokenizerFast,\n",
    "    )\n",
    "    import tokenizers\n",
    "    import transformers\n",
    "\n",
    "    def get_char_probs(texts, predictions, tokenizer):\n",
    "        results = [np.zeros(len(t)) for t in texts]\n",
    "        for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "            encoded = tokenizer(\n",
    "                text, add_special_tokens=True, return_offsets_mapping=True\n",
    "            )\n",
    "            prev_pred = 0\n",
    "            prev_end = -1\n",
    "            for idx, (offset_mapping, pred) in enumerate(\n",
    "                zip(encoded[\"offset_mapping\"], prediction)\n",
    "            ):\n",
    "                start = offset_mapping[0]\n",
    "                end = offset_mapping[1]\n",
    "                results[i][start:end] = pred\n",
    "                if start != prev_end:\n",
    "                    results[i][prev_end:start] = (pred + prev_pred) / 2\n",
    "                prev_pred = pred\n",
    "                prev_end = end\n",
    "        return results\n",
    "\n",
    "    tokenizer = DebertaV2TokenizerFast.from_pretrained(\"../input/get-token/tokenizer\")\n",
    "    max_len = 354\n",
    "    # oof作成\n",
    "\n",
    "    p = Path(\"../input/dict-oof-exp093-099/exp099-nbme-microsoft-deberta-v3-large/\")\n",
    "    oof = []\n",
    "    for f in p.glob(\"*fold*.jb\"):\n",
    "        tmpdic = joblib.load(f)\n",
    "        oof.append(pd.DataFrame(tmpdic))\n",
    "    oof = pd.concat(oof).sort_values(\"id\").reset_index(drop=True)\n",
    "    char_probs = get_char_probs(\n",
    "        oof[\"pn_history\"].values, oof[[i for i in range(max_len)]].values, tokenizer\n",
    "    )\n",
    "    return char_probs, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:48:38.608671Z",
     "iopub.status.busy": "2022-05-03T03:48:38.607664Z",
     "iopub.status.idle": "2022-05-03T03:49:15.846626Z",
     "shell.execute_reply": "2022-05-03T03:49:15.846024Z",
     "shell.execute_reply.started": "2022-05-03T02:40:45.604423Z"
    },
    "papermill": {
     "duration": 37.271394,
     "end_time": "2022-05-03T03:49:15.846775",
     "exception": false,
     "start_time": "2022-05-03T03:48:38.575381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp099_char_probs, oof099 = exp099_oof_char_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024727,
     "end_time": "2022-05-03T03:49:15.897140",
     "exception": false,
     "start_time": "2022-05-03T03:49:15.872413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024637,
     "end_time": "2022-05-03T03:49:15.946900",
     "exception": false,
     "start_time": "2022-05-03T03:49:15.922263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## exp096 roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:49:16.001388Z",
     "iopub.status.busy": "2022-05-03T03:49:16.000728Z",
     "iopub.status.idle": "2022-05-03T03:49:16.013796Z",
     "shell.execute_reply": "2022-05-03T03:49:16.013133Z",
     "shell.execute_reply.started": "2022-05-03T02:41:22.672758Z"
    },
    "papermill": {
     "duration": 0.042026,
     "end_time": "2022-05-03T03:49:16.013962",
     "exception": false,
     "start_time": "2022-05-03T03:49:15.971936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp096_oof_char_prob():\n",
    "    import tokenizers\n",
    "    import transformers\n",
    "\n",
    "    def get_char_probs(texts, predictions, tokenizer):\n",
    "        results = [np.zeros(len(t)) for t in texts]\n",
    "        for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "            encoded = tokenizer(\n",
    "                text, add_special_tokens=True, return_offsets_mapping=True\n",
    "            )\n",
    "            prev_pred = 0\n",
    "            prev_end = -1\n",
    "            for idx, (offset_mapping, pred) in enumerate(\n",
    "                zip(encoded[\"offset_mapping\"], prediction)\n",
    "            ):\n",
    "                start = offset_mapping[0]\n",
    "                end = offset_mapping[1]\n",
    "                results[i][start:end] = pred\n",
    "                if start != prev_end:\n",
    "                    results[i][prev_end:start] = (pred + prev_pred) / 2\n",
    "                prev_pred = pred\n",
    "                prev_end = end\n",
    "        return results\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"../input/exp093-roberta-large-leakage-pseudo-labeling-ssl/tokenizer\",\n",
    "        trim_offsets=False,\n",
    "    )\n",
    "    max_len = 321\n",
    "\n",
    "    # oof作成\n",
    "    p = Path(\"../input/dict-oof-exp093-099/exp096-nbme-roberta-large/\")\n",
    "    oof = []\n",
    "    for f in p.glob(\"*fold*.jb\"):\n",
    "        tmpdic = joblib.load(f)\n",
    "        oof.append(pd.DataFrame(tmpdic))\n",
    "    oof = pd.concat(oof).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "    char_probs = get_char_probs(\n",
    "        oof[\"pn_history\"].values, oof[[i for i in range(max_len)]].values, tokenizer\n",
    "    )\n",
    "    return char_probs, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:49:16.070117Z",
     "iopub.status.busy": "2022-05-03T03:49:16.069325Z",
     "iopub.status.idle": "2022-05-03T03:49:59.782519Z",
     "shell.execute_reply": "2022-05-03T03:49:59.781879Z",
     "shell.execute_reply.started": "2022-05-03T02:41:22.687802Z"
    },
    "papermill": {
     "duration": 43.742886,
     "end_time": "2022-05-03T03:49:59.782699",
     "exception": false,
     "start_time": "2022-05-03T03:49:16.039813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp096_char_probs, oof096 = exp096_oof_char_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.026158,
     "end_time": "2022-05-03T03:49:59.836401",
     "exception": false,
     "start_time": "2022-05-03T03:49:59.810243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024719,
     "end_time": "2022-05-03T03:49:59.887281",
     "exception": false,
     "start_time": "2022-05-03T03:49:59.862562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## exp098 spanbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:49:59.945996Z",
     "iopub.status.busy": "2022-05-03T03:49:59.945214Z",
     "iopub.status.idle": "2022-05-03T03:49:59.952387Z",
     "shell.execute_reply": "2022-05-03T03:49:59.951840Z",
     "shell.execute_reply.started": "2022-05-03T02:42:06.258768Z"
    },
    "papermill": {
     "duration": 0.040151,
     "end_time": "2022-05-03T03:49:59.952530",
     "exception": false,
     "start_time": "2022-05-03T03:49:59.912379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp098_oof_char_prob():\n",
    "    import tokenizers\n",
    "    import transformers\n",
    "\n",
    "    def get_char_probs(texts, predictions, tokenizer):\n",
    "        results = [np.zeros(len(t)) for t in texts]\n",
    "        for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "            encoded = tokenizer(\n",
    "                text, add_special_tokens=True, return_offsets_mapping=True\n",
    "            )\n",
    "            prev_pred = 0\n",
    "            prev_end = -1\n",
    "            for idx, (offset_mapping, pred) in enumerate(\n",
    "                zip(encoded[\"offset_mapping\"], prediction)\n",
    "            ):\n",
    "                start = offset_mapping[0]\n",
    "                end = offset_mapping[1]\n",
    "                results[i][start:end] = pred\n",
    "                if start != prev_end:\n",
    "                    results[i][prev_end:start] = (pred + prev_pred) / 2\n",
    "                prev_pred = pred\n",
    "                prev_end = end\n",
    "        return results\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"../input/exp094/tokenizer\", trim_offsets=False\n",
    "    )\n",
    "    max_len = 361\n",
    "\n",
    "    # oof作成\n",
    "    p = Path(\"../input/dict-oof-exp093-099/exp098/\")\n",
    "    oof = []\n",
    "    for f in p.glob(\"*fold*.jb\"):\n",
    "        tmpdic = joblib.load(f)\n",
    "        oof.append(pd.DataFrame(tmpdic))\n",
    "    oof = pd.concat(oof).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "    char_probs = get_char_probs(\n",
    "        oof[\"pn_history\"].values, oof[[i for i in range(max_len)]].values, tokenizer\n",
    "    )\n",
    "    return char_probs, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:50:00.008418Z",
     "iopub.status.busy": "2022-05-03T03:50:00.007643Z",
     "iopub.status.idle": "2022-05-03T03:50:40.233334Z",
     "shell.execute_reply": "2022-05-03T03:50:40.232750Z",
     "shell.execute_reply.started": "2022-05-03T02:42:06.271264Z"
    },
    "papermill": {
     "duration": 40.255728,
     "end_time": "2022-05-03T03:50:40.233501",
     "exception": false,
     "start_time": "2022-05-03T03:49:59.977773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp098_char_probs, oof098 = exp098_oof_char_prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025,
     "end_time": "2022-05-03T03:50:40.334627",
     "exception": false,
     "start_time": "2022-05-03T03:50:40.309627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## exp097 biolinkbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:50:40.391542Z",
     "iopub.status.busy": "2022-05-03T03:50:40.390846Z",
     "iopub.status.idle": "2022-05-03T03:50:40.402353Z",
     "shell.execute_reply": "2022-05-03T03:50:40.402855Z",
     "shell.execute_reply.started": "2022-05-03T02:42:46.630850Z"
    },
    "papermill": {
     "duration": 0.041535,
     "end_time": "2022-05-03T03:50:40.403043",
     "exception": false,
     "start_time": "2022-05-03T03:50:40.361508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp097_oof_char_prob():\n",
    "    import tokenizers\n",
    "    import transformers\n",
    "\n",
    "    def get_char_probs(texts, predictions, tokenizer):\n",
    "        results = [np.zeros(len(t)) for t in texts]\n",
    "        for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "            encoded = tokenizer(\n",
    "                text, add_special_tokens=True, return_offsets_mapping=True\n",
    "            )\n",
    "            prev_pred = 0\n",
    "            prev_end = -1\n",
    "            for idx, (offset_mapping, pred) in enumerate(\n",
    "                zip(encoded[\"offset_mapping\"], prediction)\n",
    "            ):\n",
    "                start = offset_mapping[0]\n",
    "                end = offset_mapping[1]\n",
    "                results[i][start:end] = pred\n",
    "                if start != prev_end:\n",
    "                    results[i][prev_end:start] = (pred + prev_pred) / 2\n",
    "                prev_pred = pred\n",
    "                prev_end = end\n",
    "        return results\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"../input/exp095/tokenizer\", trim_offsets=False\n",
    "    )\n",
    "    max_len = 321\n",
    "\n",
    "    # oof作成\n",
    "    p = Path(\"../input/dict-oof-exp093-099/exp097/\")\n",
    "    oof = []\n",
    "    for f in p.glob(\"*fold*.jb\"):\n",
    "        tmpdic = joblib.load(f)\n",
    "        oof.append(pd.DataFrame(tmpdic))\n",
    "    oof = pd.concat(oof).sort_values(\"id\").reset_index(drop=True)\n",
    "\n",
    "    char_probs = get_char_probs(\n",
    "        oof[\"pn_history\"].values, oof[[i for i in range(max_len)]].values, tokenizer\n",
    "    )\n",
    "    return char_probs, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:50:40.458368Z",
     "iopub.status.busy": "2022-05-03T03:50:40.457704Z",
     "iopub.status.idle": "2022-05-03T03:51:18.478801Z",
     "shell.execute_reply": "2022-05-03T03:51:18.479288Z",
     "shell.execute_reply.started": "2022-05-03T02:42:46.646184Z"
    },
    "papermill": {
     "duration": 38.051065,
     "end_time": "2022-05-03T03:51:18.479528",
     "exception": false,
     "start_time": "2022-05-03T03:50:40.428463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp097_char_probs, oof097=exp097_oof_char_prob()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T04:18:19.25306Z",
     "iopub.status.busy": "2022-04-24T04:18:19.252274Z",
     "iopub.status.idle": "2022-04-24T04:18:19.258541Z",
     "shell.execute_reply": "2022-04-24T04:18:19.257831Z",
     "shell.execute_reply.started": "2022-04-24T04:18:19.253004Z"
    },
    "papermill": {
     "duration": 0.024845,
     "end_time": "2022-05-03T03:51:18.529731",
     "exception": false,
     "start_time": "2022-05-03T03:51:18.504886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## wの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:51:18.585058Z",
     "iopub.status.busy": "2022-05-03T03:51:18.584272Z",
     "iopub.status.idle": "2022-05-03T03:51:18.618804Z",
     "shell.execute_reply": "2022-05-03T03:51:18.618233Z",
     "shell.execute_reply.started": "2022-05-03T03:45:55.313305Z"
    },
    "papermill": {
     "duration": 0.062567,
     "end_time": "2022-05-03T03:51:18.618963",
     "exception": false,
     "start_time": "2022-05-03T03:51:18.556396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df[\"location_for_create_labels\"] = [ast.literal_eval(f\"[]\")] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, \"location\"]\n",
    "        if lst:\n",
    "            new_lst = \";\".join(lst)\n",
    "            df.loc[i, \"location_for_create_labels\"] = ast.literal_eval(\n",
    "                f'[[\"{new_lst}\"]]'\n",
    "            )\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df[\"location_for_create_labels\"].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_raw_location_annotation(\n",
    "    char_probs: \"list[np.ndarray]\", pn_histories: \"list[str]\", th: float = 0.5\n",
    ") -> \"tuple[list[list[tuple[int,int]]], list[list[str]]]\":\n",
    "    \"\"\"前処理なしのlocationと抜き出し\"\"\"\n",
    "    locations = []\n",
    "    for char_prob in char_probs:\n",
    "        location = np.where(char_prob >= th)[0]\n",
    "        location = [\n",
    "            list(g)\n",
    "            for _, g in itertools.groupby(\n",
    "                location, key=lambda n, c=itertools.count(): n - next(c)\n",
    "            )\n",
    "        ]\n",
    "        location = [(min(r), max(r) + 1) for r in location]\n",
    "        locations.append(location)\n",
    "\n",
    "    annotations = []\n",
    "    for text, location in zip(pn_histories, locations):\n",
    "        annotation = []\n",
    "        for i, j in location:\n",
    "            annotation.append(text[i:j])\n",
    "        annotations.append(annotation)\n",
    "    return locations, annotations\n",
    "\n",
    "\n",
    "def remove_white_space_from_head(\n",
    "    locations: \"list[list[tuple[int,int]]]\", annotations: \"list[list[str]]\"\n",
    ") -> \"tuple[list[list[tuple[int,int]]], list[list[str]]]\":\n",
    "    \"\"\"先頭の後処理。空白や改行等を抜く\"\"\"\n",
    "    # pp\n",
    "    to_delete = {\" \", \"\\n\", \"\\r\"}\n",
    "    annotations2 = []\n",
    "    locations2 = []\n",
    "    for annotation, location in zip(annotations, locations):\n",
    "        new_annotation = []\n",
    "        new_location = []\n",
    "        if len(annotation) == 0:\n",
    "            annotations2.append([])\n",
    "            locations2.append([])\n",
    "            continue\n",
    "        for anno_seg, (i, j) in zip(annotation, location):\n",
    "            while anno_seg and anno_seg[0] in to_delete:  # 先頭から変なのを抜いていきます。\n",
    "                anno_seg = anno_seg[1:]\n",
    "                i += 1\n",
    "            new_annotation.append(anno_seg)\n",
    "            new_location.append((i, j))\n",
    "        annotations2.append(new_annotation)\n",
    "        locations2.append(new_location)\n",
    "    return locations2, annotations2\n",
    "\n",
    "\n",
    "def get_results(char_probs: \"list[np.ndarray]\", pn_histories: \"list[str]\", th=0.5):\n",
    "    \"\"\"文字ごとの出力確率と文章→後処理→提出用結果を生成\"\"\"\n",
    "    locations, annotations = get_raw_location_annotation(\n",
    "        char_probs, pn_histories, th=th\n",
    "    )\n",
    "    locations, annotations = remove_white_space_from_head(\n",
    "        locations, annotations\n",
    "    )  # 後処理1\n",
    "    results = []\n",
    "    for loc in locations:\n",
    "        result = [f\"{i} {j}\" for i, j in loc]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(\";\")]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(\n",
    "            np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0\n",
    "        )\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n",
    "\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def mix_char_probs(probs_list: \"list[list[np.ndarray]]\", w_list: \"list[float]\"):\n",
    "    \"\"\"複数の char_probs と w_list で指定した重みで線形結合する\"\"\"\n",
    "    # Optuna 探索だと assert で落ちる可能性があるので雑にコメントアウト\n",
    "    # assert sum(w_list)==1.0\n",
    "    # assert all([0<=w<=1 for w in w_list])\n",
    "    # assert len(probs_list) == len(w_list)\n",
    "    ret = []\n",
    "    for char_prob_list in zip(*probs_list):\n",
    "        tmp = np.zeros_like(char_prob_list[0])\n",
    "        for w, char_prob in zip(w_list, char_prob_list):\n",
    "            tmp += w * char_prob\n",
    "        ret.append(tmp)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:51:18.683832Z",
     "iopub.status.busy": "2022-05-03T03:51:18.683122Z",
     "iopub.status.idle": "2022-05-03T03:51:18.685352Z",
     "shell.execute_reply": "2022-05-03T03:51:18.685869Z",
     "shell.execute_reply.started": "2022-05-03T02:43:24.175410Z"
    },
    "papermill": {
     "duration": 0.041055,
     "end_time": "2022-05-03T03:51:18.686040",
     "exception": false,
     "start_time": "2022-05-03T03:51:18.644985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_optimal_weight(oofs: list, in_char_probs: list) -> list:\n",
    "    assert len(oofs) == len(in_char_probs)\n",
    "    truths = create_labels_for_scoring(oofs[0])\n",
    "    w_range = np.arange(0.0, 1.0, 0.1)\n",
    "    if len(oofs) == 1:\n",
    "        print(\"oofs length should be more than 1\")\n",
    "        raise ValueError()\n",
    "    else:\n",
    "        w_list = list(itertools.product(w_range, repeat=len(oofs) - 1))\n",
    "        best_score = -1.0\n",
    "        best_th = -1.0\n",
    "        best_w = None\n",
    "        for w_combination in tqdm(w_list):\n",
    "            w_last = 1.0 - sum(w_combination)\n",
    "            w_combination = list(w_combination)\n",
    "            w_combination.append(w_last)\n",
    "            char_probs = [np.zeros_like(char_prob) for char_prob in in_char_probs[0]]\n",
    "            for i, _ in enumerate(char_probs):\n",
    "                for w, in_char_prob in zip(w_combination, in_char_probs):\n",
    "                    char_probs[i] += w * in_char_prob[i]\n",
    "                    # break\n",
    "            for th in np.arange(0.5, 0.6, 0.1):\n",
    "                th = np.round(th, 2)\n",
    "                results = get_results(\n",
    "                    char_probs, oofs[0][\"pn_history\"].to_numpy(), th=th\n",
    "                )\n",
    "                preds = get_predictions(results)\n",
    "                score = get_score(truths, preds)\n",
    "                if best_score < score:\n",
    "                    best_th = th\n",
    "                    best_score = score\n",
    "                    best_w = w_combination\n",
    "        return best_w, best_th, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:51:18.741647Z",
     "iopub.status.busy": "2022-05-03T03:51:18.740960Z",
     "iopub.status.idle": "2022-05-03T03:51:18.764849Z",
     "shell.execute_reply": "2022-05-03T03:51:18.763984Z",
     "shell.execute_reply.started": "2022-05-03T02:43:24.191266Z"
    },
    "papermill": {
     "duration": 0.052199,
     "end_time": "2022-05-03T03:51:18.765012",
     "exception": false,
     "start_time": "2022-05-03T03:51:18.712813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof099[\"char_probs\"] = exp099_char_probs\n",
    "oof096[\"char_probs\"] = exp096_char_probs\n",
    "oof098[\"char_probs\"] = exp098_char_probs\n",
    "oof097[\"char_probs\"] = exp097_char_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:51:18.836414Z",
     "iopub.status.busy": "2022-05-03T03:51:18.830399Z",
     "iopub.status.idle": "2022-05-03T03:51:19.572675Z",
     "shell.execute_reply": "2022-05-03T03:51:19.572068Z",
     "shell.execute_reply.started": "2022-05-03T02:50:27.717531Z"
    },
    "papermill": {
     "duration": 0.782298,
     "end_time": "2022-05-03T03:51:19.572819",
     "exception": false,
     "start_time": "2022-05-03T03:51:18.790521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def get_optimal_weight_for_optuna(\n",
    "    oofs: list, in_char_probs: list, w_combination, th\n",
    ") -> list:\n",
    "    assert len(oofs) == len(in_char_probs)\n",
    "    assert len(oofs) == len(w_combination)\n",
    "\n",
    "    truths = create_labels_for_scoring(oofs[0])\n",
    "    if len(oofs) == 1:\n",
    "        print(\"oofs length should be more than 1\")\n",
    "        raise ValueError()\n",
    "    best_score = -1.0\n",
    "    best_th = -1.0\n",
    "    best_w = None\n",
    "    char_probs = [np.zeros_like(char_prob) for char_prob in in_char_probs[0]]\n",
    "    for i, _ in enumerate(char_probs):\n",
    "        for w, in_char_prob in zip(w_combination, in_char_probs):\n",
    "            char_probs[i] += w * in_char_prob[i]\n",
    "    th = np.round(th, 2)\n",
    "    results = get_results(char_probs, oofs[0][\"pn_history\"].to_numpy(), th=th)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(truths, preds)\n",
    "    if best_score < score:\n",
    "        best_th = th\n",
    "        best_score = score\n",
    "        best_w = w_combination\n",
    "    return best_w, best_th, best_score\n",
    "\n",
    "\n",
    "def search_weight(oofs: list, in_char_probs: list, timeout) -> list:\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        optuna_param = {\n",
    "            \"w1\": trial.suggest_uniform(\"w1\", 0.0, 1.0),\n",
    "            \"w2\": trial.suggest_uniform(\"w2\", 0.0, 1.0),\n",
    "            \"w3\": trial.suggest_uniform(\"w3\", 0.0, 1.0),\n",
    "            \"w4\": trial.suggest_uniform(\"w4\", 0.0, 1.0),\n",
    "            \"th\": trial.suggest_uniform(\"th\", 0.0, 1.0),\n",
    "        }\n",
    "        weight_sum = (\n",
    "            optuna_param[\"w1\"]\n",
    "            + optuna_param[\"w2\"]\n",
    "            + optuna_param[\"w3\"]\n",
    "            + optuna_param[\"w4\"]\n",
    "        )\n",
    "        w_combination = [\n",
    "            optuna_param[\"w1\"] / weight_sum,\n",
    "            optuna_param[\"w2\"] / weight_sum,\n",
    "            optuna_param[\"w3\"] / weight_sum,\n",
    "            optuna_param[\"w4\"] / weight_sum,\n",
    "        ]\n",
    "        th = optuna_param[\"th\"] / weight_sum\n",
    "        best_w, best_th, score = get_optimal_weight_for_optuna(\n",
    "            oofs, in_char_probs, w_combination, th\n",
    "        )\n",
    "        print(f\"w: {best_w}  th:{th:.3f}  score:{score:.5f}\")\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(multivariate=True, group=True, seed=42),\n",
    "    )\n",
    "    study.optimize(objective, timeout=timeout)\n",
    "\n",
    "    print(f\"best parameter = {study.best_trial.params}\")\n",
    "    weight_sum = (\n",
    "        study.best_trial.params[\"w1\"]\n",
    "        + study.best_trial.params[\"w2\"]\n",
    "        + study.best_trial.params[\"w3\"]\n",
    "        + study.best_trial.params[\"w4\"]\n",
    "    )\n",
    "    w_combination = [\n",
    "        study.best_trial.params[\"w1\"] / weight_sum,\n",
    "        study.best_trial.params[\"w2\"] / weight_sum,\n",
    "        study.best_trial.params[\"w3\"] / weight_sum,\n",
    "        study.best_trial.params[\"w4\"] / weight_sum,\n",
    "    ]\n",
    "    th = study.best_trial.params[\"th\"] / weight_sum\n",
    "    print(f\"weight: {w_combination}, th: {th}\")\n",
    "    best_w, best_th, score = get_optimal_weight_for_optuna(\n",
    "        oofs, in_char_probs, w_combination, th\n",
    "    )\n",
    "    return best_w, best_th, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:51:19.643545Z",
     "iopub.status.busy": "2022-05-03T03:51:19.637807Z",
     "iopub.status.idle": "2022-05-03T05:12:07.524578Z",
     "shell.execute_reply": "2022-05-03T05:12:07.523794Z",
     "shell.execute_reply.started": "2022-05-03T03:46:20.350154Z"
    },
    "papermill": {
     "duration": 4847.926527,
     "end_time": "2022-05-03T05:12:07.524767",
     "exception": false,
     "start_time": "2022-05-03T03:51:19.598240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = []\n",
    "ths = []\n",
    "val_scores = []\n",
    "for fold in range(4):\n",
    "    print(\"fold\", fold)\n",
    "    oof099_train = oof099.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    oof099_val = oof099.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    oof096_train = oof096.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    oof096_val = oof096.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    oof098_train = oof098.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    oof098_val = oof098.query(\"fold==@fold\").reset_index(drop=True)\n",
    "    oof097_train = oof097.query(\"fold!=@fold\").reset_index(drop=True)\n",
    "    oof097_val = oof097.query(\"fold==@fold\").reset_index(drop=True)\n",
    "\n",
    "    train_oof_list = [oof099_train, oof096_train, oof098_train, oof097_train]\n",
    "    train_char_probs_list = [oof[\"char_probs\"].to_list() for oof in train_oof_list]\n",
    "    val_oof_list = [oof099_val, oof096_val, oof098_val, oof097_val]\n",
    "    val_char_probs_list = [oof[\"char_probs\"].to_list() for oof in val_oof_list]\n",
    "\n",
    "    w, bt, bs = search_weight(train_oof_list, train_char_probs_list, timeout=1200)\n",
    "    print(f\"================ fold {fold} =================\")\n",
    "    print(w, bt, bs)\n",
    "    print(f\"==============================================\")\n",
    "    # 評価\n",
    "    truths = create_labels_for_scoring(val_oof_list[0])\n",
    "    char_probs = mix_char_probs(val_char_probs_list, w)\n",
    "    results = get_results(char_probs, val_oof_list[0][\"pn_history\"].to_numpy(), th=bt)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(truths, preds)\n",
    "    weights.append(w)\n",
    "    ths.append(bt)\n",
    "    val_scores.append(score)\n",
    "    print(\"val score\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T05:12:08.547116Z",
     "iopub.status.busy": "2022-05-03T05:12:08.546442Z",
     "iopub.status.idle": "2022-05-03T05:12:08.549841Z",
     "shell.execute_reply": "2022-05-03T05:12:08.550285Z",
     "shell.execute_reply.started": "2022-05-03T03:47:41.345527Z"
    },
    "papermill": {
     "duration": 0.512356,
     "end_time": "2022-05-03T05:12:08.550492",
     "exception": false,
     "start_time": "2022-05-03T05:12:08.038136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"weights: {weights}\")\n",
    "print(f\"ths: {ths}\")\n",
    "print(f\"val_scores: {val_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T05:12:09.555427Z",
     "iopub.status.busy": "2022-05-03T05:12:09.554707Z",
     "iopub.status.idle": "2022-05-03T05:12:09.558249Z",
     "shell.execute_reply": "2022-05-03T05:12:09.557651Z",
     "shell.execute_reply.started": "2022-05-03T03:47:41.353459Z"
    },
    "papermill": {
     "duration": 0.510054,
     "end_time": "2022-05-03T05:12:09.558405",
     "exception": false,
     "start_time": "2022-05-03T05:12:09.048351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_threshold(oof: list, char_probs: list, truths, timeout) -> list:\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        optuna_param = {\n",
    "            \"th\": trial.suggest_uniform(\"th\", 0.0, 1.0),\n",
    "        }\n",
    "        th = optuna_param[\"th\"]\n",
    "        results = get_results(char_probs, oof[\"pn_history\"].to_numpy(), th=th)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(truths, preds)\n",
    "        print(f\"th:{th:.3f}  score:{score:.5f}\")\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(multivariate=True, group=True, seed=42),\n",
    "    )\n",
    "    study.optimize(objective, timeout=timeout)\n",
    "\n",
    "    print(f\"best parameter = {study.best_trial.params}\")\n",
    "\n",
    "    th = study.best_trial.params[\"th\"]\n",
    "    print(f\"best th: {th}\")\n",
    "    results = get_results(char_probs, oof[\"pn_history\"].to_numpy(), th=th)\n",
    "    preds = get_predictions(results)\n",
    "    score = get_score(truths, preds)\n",
    "    return th, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T05:12:10.564088Z",
     "iopub.status.busy": "2022-05-03T05:12:10.563383Z",
     "iopub.status.idle": "2022-05-03T05:22:23.346112Z",
     "shell.execute_reply": "2022-05-03T05:22:23.345495Z",
     "shell.execute_reply.started": "2022-05-03T03:47:42.072651Z"
    },
    "papermill": {
     "duration": 613.287625,
     "end_time": "2022-05-03T05:22:23.346345",
     "exception": false,
     "start_time": "2022-05-03T05:12:10.058720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# しきい値の探索\n",
    "w = np.zeros(4)\n",
    "for weight in weights:\n",
    "    w += np.array(weight)\n",
    "w = list(w / len(weights))\n",
    "char_probs = mix_char_probs(\n",
    "    [exp099_char_probs, exp096_char_probs, exp098_char_probs, exp097_char_probs], w\n",
    ")\n",
    "\n",
    "## ============== 一応 th の平均でも score をだす =======================\n",
    "th = sum(ths) / len(ths)\n",
    "results = get_results(char_probs, oof096[\"pn_history\"].to_numpy(), th=th)\n",
    "preds = get_predictions(results)\n",
    "score = get_score(truths, preds)\n",
    "print(f\"th:{th:.3f}  score:{score:.5f}\")\n",
    "## ==================================================================\n",
    "\n",
    "\n",
    "truths = create_labels_for_scoring(oof096)\n",
    "best_th, score = search_threshold(oof096, char_probs, truths, timeout=600)\n",
    "print(f\"final weights: {w}\")\n",
    "print(f\"best_th: {best_th}, best_score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.632551,
     "end_time": "2022-05-03T05:22:24.616360",
     "exception": false,
     "start_time": "2022-05-03T05:22:23.983809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T03:12:01.956752Z",
     "iopub.status.busy": "2022-05-03T03:12:01.956452Z",
     "iopub.status.idle": "2022-05-03T03:12:26.334571Z",
     "shell.execute_reply": "2022-05-03T03:12:26.333638Z",
     "shell.execute_reply.started": "2022-05-03T03:12:01.956721Z"
    },
    "papermill": {
     "duration": 0.631469,
     "end_time": "2022-05-03T05:22:25.884993",
     "exception": false,
     "start_time": "2022-05-03T05:22:25.253524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.632062,
     "end_time": "2022-05-03T05:22:27.144585",
     "exception": false,
     "start_time": "2022-05-03T05:22:26.512523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5651.849675,
   "end_time": "2022-05-03T05:22:30.773804",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-03T03:48:18.924129",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
