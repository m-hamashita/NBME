{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1651311680734,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "Ic8N2I-_AuR_",
    "outputId": "134f23b1-2c94-4be2-8d43-47de93807785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 30 14:23:10 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   33C    P0    50W / 400W |      0MiB / 40536MiB |      0%      Default |\r\n",
      "|                               |                      |             Disabled |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi | head -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yml\r\n",
      "deberta-v2-3-fast-tokenizer\r\n",
      "features.csv\r\n",
      "nbme-score-clinical-patient-notes.zip\r\n",
      "patient_notes.csv\r\n",
      "roberta-large-self-supervised-learning-9epoch\r\n",
      "roberta-large-self-supervised-learning-9epoch.zip\r\n",
      "sample_submission.csv\r\n",
      "test.csv\r\n",
      "train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16301,
     "status": "ok",
     "timestamp": 1651311697288,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "7GP9_WE_qfhx",
    "outputId": "7f9bb416-a185-4efb-acbf-bd38771ccfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1651311723025,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "UIbnuTIAqbcP"
   },
   "outputs": [],
   "source": [
    "# # colab用設定\n",
    "# # もしcolab上だったら実行するものを以下のif文で指定する\n",
    "# import sys\n",
    "# # Colaboratory環境ならTrue\n",
    "# is_colab='google.colab' in sys.modules\n",
    "# # Kaggle Notebook環境ならTrue\n",
    "# is_kaggle='kaggle_web_client' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61062,
     "status": "ok",
     "timestamp": 1651311784637,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "TDnZasm0v_Ww",
    "outputId": "be61105e-8e11-4c9c-d203-8ef7e34a5eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/kaggle\", line 5, in <module>\n",
      "    from kaggle.cli import main\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/kaggle/__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/kaggle/api/kaggle_api_extended.py\", line 164, in authenticate\n",
      "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
      "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
      "unzip:  cannot find or open ../input/roberta-large-self-supervised-learning-9epoch.zip, ../input/roberta-large-self-supervised-learning-9epoch.zip.zip or ../input/roberta-large-self-supervised-learning-9epoch.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# if is_colab:\n",
    "#     # from google.colab import drive\n",
    "#     # drive.mount('/content/drive')\n",
    "#     # install pakages\n",
    "#     ! apt install -qq vim fish htop tree\n",
    "#     ! ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi #デフォのnvidia-smiがぶっ壊れてる\n",
    "#     # fileの移し替え\n",
    "#     !cp -r /content/drive/MyDrive/dotfiles_for_colab/.vscode/ /content/\n",
    "#     !mkdir /root/.kaggle/\n",
    "#     !cp /content/drive/MyDrive/dotfiles_for_colab/kaggle.json /root/.kaggle/kaggle.json\n",
    "#     !chmod 600 ~/.kaggle/kaggle.json\n",
    "#     !kaggle competitions download -c nbme-score-clinical-patient-notes -p /content/input/nbme-score-clinical-patient-notes/\n",
    "#     !unzip /content/input/nbme-score-clinical-patient-notes/nbme-score-clinical-patient-notes.zip -d /content/input/nbme-score-clinical-patient-notes/\n",
    "#     !rm /content/input/nbme-score-clinical-patient-notes/nbme-score-clinical-patient-notes.zip\n",
    "#     # kaggleからデータのダウンロード\n",
    "#     !kaggle datasets download -d nbroad/deberta-v2-3-fast-tokenizer -p /content/input/deberta-v2-3-fast-tokenizer/\n",
    "#     !unzip /content/input/deberta-v2-3-fast-tokenizer/deberta-v2-3-fast-tokenizer.zip -d /content/input/deberta-v2-3-fast-tokenizer/\n",
    "#     !rm /content/input/deberta-v2-3-fast-tokenizer/deberta-v2-3-fast-tokenizer.zip\n",
    "# !kaggle datasets download -d mpeg31/roberta-large-self-supervised-learning-9epoch -p ../input\n",
    "# !unzip ../input/roberta-large-self-supervised-learning-9epoch.zip -d ../input/roberta-large-self-supervised-learning-9epoch/\n",
    "    \n",
    "#     # pip install\n",
    "#     !pip install -q transformers wandb sentencepiece\n",
    "#     !mkdir /content/notebook\n",
    "#     !cp /content/drive/MyDrive/exp093/pl_train.csv /content/input/\n",
    "#     #作業用directoryの移動\n",
    "#     %cd /content/notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651311784637,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "I35xIFQiv1xD",
    "outputId": "3b714204-8c21-4c56-cfc1-9ec6509352f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/notebook\n"
     ]
    }
   ],
   "source": [
    "# %cd /content/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7426d7d"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3148,
     "status": "ok",
     "timestamp": 1651311787780,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "797404f7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.core.display import display\n",
    "import random\n",
    "import re\n",
    "import yaml\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import torch\n",
    "from logging import Logger, getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import wandb\n",
    "from wandb.sdk.wandb_config import Config\n",
    "\n",
    "\n",
    "def init_pandas() -> None:\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", 500)\n",
    "    pd.set_option(\"display.max_columns\", 500)\n",
    "    pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "\n",
    "def get_logger(filename: str) -> Logger:\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def init_wandb(wandb_key: str) -> Config:\n",
    "\n",
    "    # from kaggle_secrets import UserSecretsClient\n",
    "    # user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = wandb_key\n",
    "    wandb.login(key=secret_value_0)\n",
    "\n",
    "#     my_ds_path = \"../input\"\n",
    "    loader = yaml.SafeLoader\n",
    "    loader.add_implicit_resolver(\n",
    "        \"tag:yaml.org,2002:float\",\n",
    "        re.compile(\n",
    "            \"\"\"^(?:\n",
    "         [-+]?(?:[0-9][0-9_]*)\\\\.[0-9_]*(?:[eE][-+]?[0-9]+)?\n",
    "        |[-+]?(?:[0-9][0-9_]*)(?:[eE][-+]?[0-9]+)\n",
    "        |\\\\.[0-9_]+(?:[eE][-+][0-9]+)?\n",
    "        |[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\\\.[0-9_]*\n",
    "        |[-+]?\\\\.(?:inf|Inf|INF)\n",
    "        |\\\\.(?:nan|NaN|NAN))$\"\"\",\n",
    "            re.X,\n",
    "        ),\n",
    "        list(\"-+0123456789.\"),\n",
    "    )\n",
    "    with open(f\"./config.yml\") as f:\n",
    "        param = yaml.load(f, Loader=loader)\n",
    "    wandb.init(project=param[\"project\"], config=param)\n",
    "    wandb.config.update(param)\n",
    "    print(f\"run name: {wandb.run.name}\")\n",
    "    return wandb.config\n",
    "\n",
    "\n",
    "def mk_output_dir(path: str) -> None:\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 6408,
     "status": "ok",
     "timestamp": 1651311794183,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "383q4PFUrZKP",
    "outputId": "e7a23b96-dde6-4df8-8acf-91f92a64646b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmpeg\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/workspace/NBME/exp093/wandb/run-20220430_142316-1hj9bhqk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mpeg/NBME-ScoreClinicalPatientNotes/runs/1hj9bhqk\" target=\"_blank\">sage-universe-28</a></strong> to <a href=\"https://wandb.ai/mpeg/NBME-ScoreClinicalPatientNotes\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run name: sage-universe-28\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from getpass import getpass\n",
    "\n",
    "# if is_kaggle:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "# elif is_colab:\n",
    "#     with open('/content/drive/MyDrive/dotfiles_for_colab/wandb_api.txt') as f:\n",
    "#         secret_value_0=f.readline()\n",
    "# else:\n",
    "#     raise ValueError()\n",
    "\n",
    "\n",
    "wandb_key = getpass()\n",
    "config = init_wandb(wandb_key=wandb_key)\n",
    "mk_output_dir(path=config.output_dir)\n",
    "logger = get_logger(\n",
    "    filename=config.output_dir+'train'\n",
    ")\n",
    "seed_everything(seed=config.seed)\n",
    "init_pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "575ae408"
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1651311794987,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "8771dcad"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "def get_score(y_true:ndarray, y_pred:ndarray) -> float:\n",
    "\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def micro_f1(preds:list, truths:list) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    \n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans:list, length=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "        \n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4675,
     "status": "ok",
     "timestamp": 1651311799657,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "c20fdb1b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "\n",
    "def create_labels_for_scoring(df:DataFrame):\n",
    "\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    \n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts:list, predictions:ndarray, tokenizer:PreTrainedTokenizer) -> list:\n",
    "    \n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        prev_pred = 0\n",
    "        prev_end = -1\n",
    "        for offset_mapping, pred in zip(encoded['offset_mapping'], prediction):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "            if start != prev_end:\n",
    "                results[i][prev_end:start] = (pred+prev_pred)/2\n",
    "            prev_pred = pred\n",
    "            prev_end = end\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def cluster_elements(xs:list) -> list:\n",
    "\n",
    "    clusters = [[]]\n",
    "    \n",
    "    if len(xs) == 0:\n",
    "        return clusters\n",
    "\n",
    "    prev_x = xs[0]-1\n",
    "    for x in xs:\n",
    "        if x == prev_x+1:\n",
    "            clusters[-1].append(x)\n",
    "        else:\n",
    "            clusters.append([x])\n",
    "        prev_x = x\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_results(char_probs:list, pn_histories:list, th:float=0.5) -> list:\n",
    "    \n",
    "    label_strs = []\n",
    "    for char_prob, pn_history in zip(char_probs, pn_histories):\n",
    "        pos_char_indices = np.where(char_prob>th)[0] + 1\n",
    "        if len(pos_char_indices)>0 and pos_char_indices[0]==1:\n",
    "            pos_char_indices=np.hstack([[0],pos_char_indices])\n",
    "        clustered_pos_char_indices = cluster_elements(xs=pos_char_indices)\n",
    "        \n",
    "        for i in range(len(clustered_pos_char_indices)):\n",
    "            # 1文字目がspaceの場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                target_idx = clustered_pos_char_indices[i][0]-1\n",
    "                if target_idx>-1 and pn_history[target_idx] != ' ':\n",
    "                    clustered_pos_char_indices[i] = np.hstack([\n",
    "                        [target_idx],\n",
    "                        clustered_pos_char_indices[i]\n",
    "                    ])\n",
    "\n",
    "            # 1文字目が\\r\\nの場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                if clustered_pos_char_indices[i][0] > 0 and clustered_pos_char_indices[i][0]+2 < len(pn_history):\n",
    "                    if pn_history[clustered_pos_char_indices[i][0]:clustered_pos_char_indices[i][0]+2] == '\\r\\n':\n",
    "                        clustered_pos_char_indices[i] = clustered_pos_char_indices[i][2:]\n",
    "\n",
    "            # 最後の2文字が\\n-の場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                target_idx = clustered_pos_char_indices[i][-1]-2\n",
    "                if target_idx>0 and pn_history[target_idx:target_idx+2]=='\\n-':\n",
    "                    clustered_pos_char_indices[i] = clustered_pos_char_indices[i][:-2]\n",
    "                \n",
    "                # yof対応\n",
    "#                 if len(clustered_pos_char_indices[i]) > 0:\n",
    "#                     target_idx = clustered_pos_char_indices[i][0]-1\n",
    "#                     if target_idx>-1 and len(clustered_pos_char_indices[i])>1 and (pn_history[target_idx:target_idx+3] in ['yof', 'YOF']):\n",
    "#                         clustered_pos_char_indices[i] = clustered_pos_char_indices[i][1:]\n",
    "\n",
    "#                     target_idx = clustered_pos_char_indices[i][-1]-3\n",
    "#                     if target_idx>-1 and len(clustered_pos_char_indices[i])>1 and (pn_history[target_idx:target_idx+3] in ['yof', 'YOF']):\n",
    "#                         clustered_pos_char_indices[i] = clustered_pos_char_indices[i][:-1]\n",
    "\n",
    "#                     if len(clustered_pos_char_indices[i])>0 and clustered_pos_char_indices[i][0]==clustered_pos_char_indices[i][-1]:\n",
    "#                         clustered_pos_char_indices[i] = np.hstack(\n",
    "#                             [\n",
    "#                                 clustered_pos_char_indices[i],\n",
    "#                                 [clustered_pos_char_indices[i][-1]+1]\n",
    "#                             ]\n",
    "#                         )\n",
    "\t\t\n",
    "        pos_char_spans = []\n",
    "        if len(clustered_pos_char_indices[0]) != 0:\n",
    "            for x in clustered_pos_char_indices:\n",
    "                if len(x)>0:\n",
    "                    pos_char_spans.append(\n",
    "                        [x[0],x[-1]]\n",
    "                    )\n",
    "        label_strs.append(\n",
    "            ';'.join([\n",
    "                f'{x[0]} {x[1]}' for x in pos_char_spans\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    return label_strs\n",
    "\n",
    "\n",
    "def get_predictions(results:list) -> list:\n",
    "    \n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_result(df_oof:DataFrame, tokenizer:PreTrainedTokenizer, max_len:int) -> tuple:\n",
    "\n",
    "    labels = create_labels_for_scoring(df_oof)\n",
    "    predictions = df_oof[[i for i in range(max_len)]].to_numpy()\n",
    "    char_probs = get_char_probs(df_oof['pn_history'].to_numpy(), predictions, tokenizer)\n",
    "    pn_histories = df_oof['pn_history'].to_list()\n",
    "    \n",
    "    score=-100\n",
    "    for th in np.arange(0.3,0.7,0.005):\n",
    "        th = np.round(th,4)\n",
    "        results = get_results(char_probs, pn_histories, th=th)\n",
    "        preds = get_predictions(results)\n",
    "        tmp_score = get_score(labels, preds)\n",
    "        if tmp_score > score:\n",
    "            best_th=th\n",
    "            score=tmp_score\n",
    "    \n",
    "    return score, best_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dc99c98"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:46:53.45023Z",
     "iopub.status.busy": "2022-04-26T23:46:53.449418Z",
     "iopub.status.idle": "2022-04-26T23:46:53.467497Z",
     "shell.execute_reply": "2022-04-26T23:46:53.466841Z",
     "shell.execute_reply.started": "2022-04-26T23:46:53.450185Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651311799657,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "PIvUkG_MqV10"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_features(features:DataFrame) -> None:\n",
    "    \n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1651311800787,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f93fc583",
    "outputId": "d4bc8fd6-65d7-42ce-ae34-c111a9500195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (14300, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (143, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_notes.shape: (42146, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_train['annotation'] = df_train['annotation'].map(lambda x: ast.literal_eval(x))\n",
    "df_train['location'] = df_train['location'].map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "features = pd.read_csv('../input/features.csv')\n",
    "preprocess_features(features)\n",
    "\n",
    "patient_notes = pd.read_csv('../input/patient_notes.csv')\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "display(df_train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651311800788,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ce0adc5c",
    "outputId": "b12f7852-3842-42c8-c03d-84ed6233c3d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location                                       feature_text                                         pn_history\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]  Family-history-of-MI-OR-Family-history-of-myoc...  HPI: 17yo M presents with palpitations. Patien...\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                 Family-history-of-thyroid-disorder  HPI: 17yo M presents with palpitations. Patien...\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]                                     Chest-pressure  HPI: 17yo M presents with palpitations. Patien...\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                              Intermittent-symptoms  HPI: 17yo M presents with palpitations. Patien...\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                                        Lightheaded  HPI: 17yo M presents with palpitations. Patien..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df_train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "df_train = df_train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1651311801176,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "66337109"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def correct_annotation(df_train:DataFrame) -> None:\n",
    "    df_train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n",
    "    df_train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n",
    "\n",
    "    df_train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n",
    "    df_train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n",
    "\n",
    "    df_train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n",
    "    df_train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n",
    "\n",
    "    df_train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n",
    "    df_train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n",
    "\n",
    "    df_train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n",
    "    df_train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n",
    "\n",
    "    df_train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n",
    "    df_train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n",
    "\n",
    "    df_train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n",
    "    df_train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n",
    "\n",
    "    df_train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n",
    "    df_train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n",
    "\n",
    "    df_train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n",
    "    df_train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n",
    "\n",
    "    df_train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n",
    "    df_train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n",
    "\n",
    "    df_train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n",
    "    df_train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n",
    "\n",
    "    df_train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n",
    "    df_train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n",
    "\n",
    "    df_train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n",
    "    df_train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n",
    "\n",
    "    df_train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n",
    "    df_train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n",
    "\n",
    "    df_train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n",
    "    df_train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n",
    "\n",
    "    df_train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n",
    "    df_train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n",
    "\n",
    "    df_train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n",
    "    df_train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n",
    "\n",
    "    df_train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n",
    "    df_train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n",
    "\n",
    "    df_train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n",
    "    df_train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n",
    "\n",
    "    df_train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n",
    "    df_train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n",
    "\n",
    "    df_train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n",
    "    df_train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n",
    "\n",
    "    df_train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n",
    "    df_train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n",
    "\n",
    "    df_train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n",
    "    df_train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n",
    "\n",
    "    df_train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n",
    "    df_train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n",
    "\n",
    "    df_train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n",
    "    df_train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n",
    "\n",
    "    df_train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n",
    "    df_train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n",
    "\n",
    "    df_train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n",
    "    df_train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n",
    "\n",
    "    df_train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n",
    "    df_train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n",
    "\n",
    "    df_train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n",
    "    df_train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n",
    "\n",
    "    df_train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n",
    "    df_train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n",
    "\n",
    "    df_train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n",
    "    df_train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n",
    "\n",
    "    df_train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n",
    "    df_train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n",
    "\n",
    "    df_train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n",
    "    df_train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n",
    "\n",
    "    df_train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n",
    "    df_train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n",
    "\n",
    "    df_train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n",
    "    df_train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n",
    "\n",
    "    df_train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n",
    "    df_train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n",
    "\n",
    "    df_train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n",
    "    df_train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n",
    "\n",
    "    df_train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n",
    "    df_train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n",
    "\n",
    "    df_train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n",
    "    df_train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n",
    "\n",
    "    df_train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n",
    "    df_train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n",
    "\n",
    "    df_train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n",
    "    df_train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n",
    "\n",
    "    df_train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n",
    "    df_train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1651311801610,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ec3a7b5f",
    "outputId": "edd5d93b-311a-4892-c168-e829dcd9c976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8181\n",
       "0    4399\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['annotation_length'] = df_train['annotation'].map(lambda x: len(x))\n",
    "display(df_train['annotation_length'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_qUU5T3qV12"
   },
   "source": [
    "# Pseudo Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651311801610,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "U9OQPqaQqV12",
    "outputId": "0193293c-9dcd-4413-c2a9-c50c443afd09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00041_000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00041_001</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>[MOM HAS THYROID PROBLEMS]</td>\n",
       "      <td>[532 556]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00041_002</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>[PRESSURE ON HER CHEST]</td>\n",
       "      <td>[263 284]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  case_num  pn_num  feature_num                  annotation   location                                       feature_text                                         pn_history  annotation_length\n",
       "13  00041_000         0      41            0                          []         []  Family-history-of-MI-OR-Family-history-of-myoc...  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  0\n",
       "14  00041_001         0      41            1  [MOM HAS THYROID PROBLEMS]  [532 556]                 Family-history-of-thyroid-disorder  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  1\n",
       "15  00041_002         0      41            2     [PRESSURE ON HER CHEST]  [263 284]                                     Chest-pressure  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[13:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 20128,
     "status": "ok",
     "timestamp": 1651311821733,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "K34gY7O1qV12"
   },
   "outputs": [],
   "source": [
    "pl_train = pd.read_csv('./pl_train.csv')\n",
    "pl_train['location'] = pl_train['location'].fillna('[]')\n",
    "pl_train['location'] = pl_train['location'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6c6437f"
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1651311822249,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ed511f87",
    "outputId": "ef8ab8db-b3e9-485c-a82b-78f26e0cf54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    3575\n",
       "1    3575\n",
       "2    3575\n",
       "3    3575\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "kf = GroupKFold(n_splits=config.n_folds)\n",
    "groups = df_train['pn_num'].to_numpy()\n",
    "df_train.loc[:, 'fold'] = -1\n",
    "for n, (train_index, val_index) in enumerate(kf.split(df_train, df_train['location'], groups)):\n",
    "    df_train.loc[val_index, 'fold'] = n\n",
    "display(df_train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651311822250,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "526e4ac9"
   },
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    display(df_train.groupby('fold').size())\n",
    "    df_train = df_train.sample(n=500, random_state=0).reset_index(drop=True)\n",
    "    display(df_train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11e2590f"
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651311822250,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "BR6m_itarTmJ"
   },
   "outputs": [],
   "source": [
    "# # The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import transformers\n",
    "\n",
    "# transformers_path = Path(transformers.__file__[:-12])\n",
    "\n",
    "# input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "# convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "# conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "# if conversion_path.exists():\n",
    "#     conversion_path.unlink()\n",
    "\n",
    "# shutil.copy(convert_file, transformers_path)\n",
    "# deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "# for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n",
    "#     if str(filename).startswith(\"deberta\"):\n",
    "#         filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n",
    "#     else:\n",
    "#         filepath = deberta_v2_path/filename\n",
    "#     if filepath.exists():\n",
    "#         filepath.unlink()\n",
    "\n",
    "#     shutil.copy(input_dir/filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "3dfd6ffec9b24babadfec07ae9b4d4f2",
      "46e47f4bb99a40d18aa19d5363d705d7",
      "c4b736fcb0e848aa9c4af1acd87fc245",
      "138066817ded4fa69b551f5f348d64d3",
      "51a576ced81f4db398a59c17ee4ed72a",
      "9e5730dbbedc453084d26fce77c8f11a",
      "c8cdc3e86a9a45dc9d793c3af5c2b200",
      "6575cc7a10f4437aa7d11fa7ceca4763",
      "67a2c064710d4776931e123353ae4d7c",
      "41f47ec442474719936603b59d907c65",
      "ab79ac7e7d4347d4b7f5532338e155fc",
      "5da8d5ce32994a09bf936227fa5edd12",
      "30b2afa7062b47fab7587476a6eca617",
      "1fd0b6fc0fae481991b0ab4503a0b755",
      "845a7583cf5c41cca875cb882249410d",
      "c171770408b142d5b1226b47d46d1f01",
      "bae1237788084a8d866042ed69d2293c",
      "5373c537d30f41aba39af4334ecf6f36",
      "ec6dd9f7b1e849bab372cb5df4b93531",
      "4f40caab4b1e4310935b17be7b5a4e93",
      "99a4d42eeb4a4bd999d74f88e20e13f6",
      "940111d655744355b867729c5edeabcf",
      "de995a2f649e4cef8c85187aeba4cd3b",
      "0da24853130543829a39f79ab1fadcd1",
      "fbb2db51a41c4a4686709c9f01e6955f",
      "f911ea9470da45c5883a305e92b9787e",
      "73ab2df54724494ba033d8b01b517392",
      "fbccff640fa3407bb8ae2a2c1f40afe2",
      "44aa0c7a57fc429aa7fa7faa7a0e9eaa",
      "800add5dca784b57af4947833d6a9eef",
      "6cb0890136fe43869dfa504840a6cdf8",
      "b696976706ad4bc2a969cb9e15a82eb7",
      "00adb1f99dc140b4a293e96d77485bbe",
      "68f2c6ede37445a09e0e3f9445cfd187",
      "3d51c94c20ad4c83bc27023439d60d91",
      "1b50897e46d74bf0977a0218c424f596",
      "869542edce0442c8898a0717f9ff4a85",
      "cec4f5657c3241eeb6d8ba7ec0efb5ef",
      "24cf07e1a7c443259917d487a83cb32b",
      "a674d7856b3646d4b58736cd6da06412",
      "4215a5ca45ce4d368cbf69610e39b499",
      "e308a1e284024d48bf2ec05ce08ac860",
      "fcbd2f47603a4a9fa5bdd7720992d5b2",
      "e4367b4d96424071be69a99e544b9727"
     ]
    },
    "executionInfo": {
     "elapsed": 5774,
     "status": "ok",
     "timestamp": 1651311828017,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "819ca57b",
    "outputId": "750eb3b3-6785-4cae-dd99-dac2a0a0277f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953b59acc1054a0fbd6026176db04879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecb0d74700e485e8e7eb831ed923471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36950e47cdbe44d1b98cca3c73f98a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4680edd39b65433183e51bc6cb35e087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('../output/exp093tokenizer/tokenizer_config.json',\n",
       " '../output/exp093tokenizer/special_tokens_map.json',\n",
       " '../output/exp093tokenizer/vocab.json',\n",
       " '../output/exp093tokenizer/merges.txt',\n",
       " '../output/exp093tokenizer/added_tokens.json',\n",
       " '../output/exp093tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# from transformers.models.deberta_v2 import DebertaV2TokenizerFast\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "\n",
    "# tokenizer = DebertaV2TokenizerFast.from_pretrained(config.tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.tokenizer,\n",
    "    trim_offsets=False\n",
    ")\n",
    "tokenizer.save_pretrained(config.output_dir+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18702,
     "status": "ok",
     "timestamp": 1651311846702,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "7d057ad3",
    "outputId": "df7ffb47-75d7-4880-9106-9e2277566073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pn_history max(lengths): 433\n",
      "feature_text max(lengths): 30\n",
      "max_len: 466\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "for text in patient_notes[\"pn_history\"].fillna(\"\").to_list():\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "pn_history_max_len = max(pn_history_lengths)\n",
    "logger.info(f\"pn_history max(lengths): {pn_history_max_len}\")\n",
    "\n",
    "features_lengths = []\n",
    "for text in features[\"feature_text\"].fillna(\"\").to_list():\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    features_lengths.append(length)\n",
    "feature_text_max_len = max(features_lengths)\n",
    "logger.info(f\"feature_text max(lengths): {feature_text_max_len}\")\n",
    "\n",
    "config.max_len = pn_history_max_len + feature_text_max_len + 3\n",
    "logger.info(f\"max_len: {config.max_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06f9f616"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1651311846703,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "1387f638"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer:PreTrainedTokenizer, \n",
    "        max_len:int,\n",
    "        feature_text_max_len:int, \n",
    "        pn_history_max_len:int, \n",
    "        df:DataFrame) -> None:\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.feature_text_max_len = feature_text_max_len\n",
    "        self.pn_history_max_len = pn_history_max_len\n",
    "        self.feature_texts = df['feature_text'].to_numpy()\n",
    "        self.pn_historys = df['pn_history'].to_numpy()\n",
    "        self.annotation_lengths = df['annotation_length'].to_numpy()\n",
    "        self.locations = df['location'].to_numpy()\n",
    "\n",
    "        \n",
    "    def prepare_input_with_fixed_position(self, pn_history:str, feature_text:str) -> dict:\n",
    "\n",
    "        pn_history_token = self.tokenizer(\n",
    "            pn_history, \n",
    "            add_special_tokens=True,\n",
    "            max_length=self.pn_history_max_len+2, \n",
    "            padding='max_length',\n",
    "            return_offsets_mapping=False)\n",
    "        \n",
    "        feature_text_token = self.tokenizer(\n",
    "            feature_text, \n",
    "            add_special_tokens=True,\n",
    "            max_length=self.feature_text_max_len+2, \n",
    "            padding='max_length',\n",
    "            return_offsets_mapping=False)\n",
    "        for k,v in feature_text_token.items():\n",
    "            feature_text_token[k] = v[1:]\n",
    "        \n",
    "\n",
    "        token = {\n",
    "            'input_ids': pn_history_token['input_ids']+feature_text_token['input_ids'],\n",
    "            'attention_mask': pn_history_token['attention_mask']+feature_text_token['attention_mask'],\n",
    "            # 'token_type_ids': pn_history_token['token_type_ids']+list(torch.ones_like(torch.tensor(feature_text_token['token_type_ids'], dtype=torch.long)))\n",
    "        }\n",
    "        for k, v in token.items():\n",
    "            token[k] = torch.tensor(v[:self.max_len], dtype=torch.long)\n",
    "        return token\n",
    "    \n",
    "    \n",
    "    def create_label(self, text:str, annotation_length:int, location_list:list) -> Tensor:\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True)\n",
    "        offset_mapping = encoded['offset_mapping']\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "        if annotation_length != 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(';')]:\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "                        \n",
    "        return torch.tensor(label[:self.max_len], dtype=torch.float)\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, item:int) -> tuple:\n",
    "        \n",
    "        inputs = self.prepare_input_with_fixed_position(\n",
    "            self.pn_historys[item],\n",
    "            self.feature_texts[item])\n",
    "        label = self.create_label(\n",
    "            self.pn_historys[item], \n",
    "            self.annotation_lengths[item], \n",
    "            self.locations[item])\n",
    "        \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "006c4b6c"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1651311847113,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "aab0ac97"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(Module):\n",
    "    \n",
    "    def __init__(self, model_name:str, config_path:str=None, pretrained:bool=False) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(\n",
    "                model_name, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(\n",
    "                config.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        self.initializer_range = 0.1\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        \n",
    "    def _init_weights(self, module:Module) -> None:\n",
    "        \n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "        \n",
    "    def feature(self, inputs:Tensor) -> Tensor:\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        \n",
    "        return last_hidden_states\n",
    "\n",
    "    \n",
    "    def forward(self, inputs:Tensor) -> Tensor:\n",
    "        \n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "class AWP:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model:Module,\n",
    "        criterion:_Loss,\n",
    "        optimizer:Optimizer,\n",
    "        adv_param:str=\"weight\",\n",
    "        adv_lr:int=1,\n",
    "        adv_eps:float=0.2,\n",
    "        start_epoch:int=0,\n",
    "        adv_step:int=1,\n",
    "        scaler=None) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion=criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.start_epoch = start_epoch\n",
    "        self.adv_step = adv_step\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "        self.scaler = scaler\n",
    "\n",
    "        \n",
    "    def attack_backward(self, inputs:Tensor, labels:Tensor, epoch:int) -> None:\n",
    "        \n",
    "        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n",
    "            return None\n",
    "        self._save() \n",
    "        for i in range(self.adv_step):\n",
    "            self._attack_step() \n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_preds = self.model(inputs)\n",
    "                adv_loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "                adv_loss = torch.masked_select(adv_loss, labels.view(-1, 1) != -1).mean()\n",
    "                adv_loss = adv_loss.mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(adv_loss).backward()\n",
    "        self._restore()\n",
    "\n",
    "        \n",
    "    def _attack_step(self) -> None:\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1])\n",
    "\n",
    "    def _save(self) -> None:\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps)\n",
    "\n",
    "                    \n",
    "    def _restore(self) -> None:\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "250ef911"
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651311847114,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "716ccfc0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from math import floor\n",
    "from torch import inference_mode\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        \n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "        \n",
    "    def update(self, val:float, n=1) -> None:\n",
    "        \n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s) -> str:\n",
    "    \n",
    "    m = floor(s / 60)\n",
    "    s -= m * 60\n",
    "    \n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent) -> str:\n",
    "    \n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    \n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3139cba-ebd0-4faf-bb86-de5f7f032293"
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1651311847729,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ef0f8033"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from logging import Logger\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer, AdamW\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch import cuda\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from wandb.sdk.wandb_config import Config\n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer_params(\n",
    "    model:Module, \n",
    "    encoder_lr:float, \n",
    "    decoder_lr:float, \n",
    "    weight_decay:float=0.0) -> list:\n",
    "\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "        'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "    return optimizer_parameters\n",
    "\n",
    "\n",
    "def get_scheduler(\n",
    "    scheduler:str, \n",
    "    optimizer:Optimizer, \n",
    "    num_warmup_steps:int, \n",
    "    num_train_steps:int, \n",
    "    num_cycles:int) -> _LRScheduler:\n",
    "    \n",
    "    if scheduler=='linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=num_warmup_steps, \n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif scheduler=='cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=num_warmup_steps, \n",
    "            num_training_steps=num_train_steps, \n",
    "            num_cycles=num_cycles\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid Scheduler Name.')\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, config:Config, tokenizer:PreTrainedTokenizer, logger:Logger) -> None:\n",
    "\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.logger = logger\n",
    "        self.device = torch.device('cuda' if cuda.is_available() else 'cpu')\n",
    "        \n",
    "        \n",
    "    def log(self, data:dict, prefix:str='') -> None:\n",
    "        \n",
    "        min_str_length = min([len(k) for k in data.keys()])\n",
    "        n_same_char_seqs = 0\n",
    "        for i in range(min_str_length):\n",
    "            s = set([k[i] for k in data.keys()])\n",
    "            if len(s)==1:\n",
    "                n_same_char_seqs+=1\n",
    "            else:\n",
    "                break\n",
    "        str_logs = [f'{k}: {v}' for k,v in data.items()]\n",
    "        s = ' '.join(\n",
    "            [l[n_same_char_seqs:].capitalize() for l in str_logs])\n",
    "        if prefix != '':\n",
    "            s = f'{prefix} - {s}'\n",
    "        self.logger.info(s)\n",
    "        wandb.log(data)\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, y_preds:Tensor, labels:Tensor, batch_size:int, loss_th:float) -> tuple:\n",
    "       \n",
    "        loss = self.criterion(y_preds.squeeze(-1), labels.squeeze(-1))\n",
    "        samplewise_losses = []\n",
    "        for i in range(batch_size):\n",
    "            samplewise_losses.append(\n",
    "                torch.masked_select(loss[i], labels[i].squeeze(-1) != -1).mean()\n",
    "            )\n",
    "        loss = torch.stack(samplewise_losses)\n",
    "        loss_filter = torch.ones(batch_size, device=self.device)\n",
    "        if loss_th is not None:\n",
    "            mask = loss > loss_th\n",
    "            n_masked = mask.sum()\n",
    "            if n_masked > 0:\n",
    "                self.logger.info(f\"{n_masked} sample's loss was removed.\")\n",
    "            loss_filter[mask] = 0.0\n",
    "        else:\n",
    "            n_masked=0\n",
    "            \n",
    "        samplewise_losses = []\n",
    "        if loss_th is None:\n",
    "            for l in samplewise_losses:\n",
    "                samplewise_losses.append(l.item())\n",
    "                \n",
    "        return (loss*loss_filter).sum()/(batch_size-n_masked), samplewise_losses\n",
    "\n",
    "        \n",
    "    def train_with_eval(\n",
    "        self, \n",
    "        model:Module, \n",
    "        fold:int, \n",
    "        dls:tuple, \n",
    "        optimizer:Optimizer, \n",
    "        epoch:int, \n",
    "        scheduler:_LRScheduler, \n",
    "        loss_th:float, \n",
    "        valid_texts:list, \n",
    "        valid_labels:ndarray,\n",
    "        n_vl:int,\n",
    "        best_score:float) -> tuple:\n",
    "        \n",
    "        tr_dl, vl_dl = dls\n",
    "        model.train()\n",
    "        scaler = cuda.amp.GradScaler(enabled=self.config.apex)\n",
    "        awp = AWP(\n",
    "            model,\n",
    "            self.criterion,\n",
    "            optimizer,\n",
    "            adv_lr=self.config.adv_lr,\n",
    "            adv_eps=self.config.adv_eps,\n",
    "            start_epoch=self.config.adv_start_epoch,\n",
    "            scaler=scaler)\n",
    "        \n",
    "        am = AverageMeter()\n",
    "        samplewise_losses = []\n",
    "        global_step = 0\n",
    "        for step, (inputs, labels) in enumerate(tr_dl):\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            batch_size = labels.size(0)\n",
    "            with cuda.amp.autocast(enabled=self.config.apex):\n",
    "                y_preds = model(inputs)\n",
    "                \n",
    "            loss, sl = self.compute_loss(\n",
    "                y_preds=y_preds, \n",
    "                labels=labels, \n",
    "                batch_size=batch_size, \n",
    "                loss_th=loss_th)\n",
    "            samplewise_losses += sl\n",
    "            if self.config.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.config.gradient_accumulation_steps\n",
    "            am.update(loss.item(), batch_size)            \n",
    "            scaler.scale(loss).backward()\n",
    "            awp.attack_backward(inputs, labels, epoch)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.config.max_grad_norm)\n",
    "            if (step + 1) % self.config.gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                if self.config.batch_scheduler:\n",
    "                    scheduler.step()\n",
    "            if step % self.config.print_freq == 0 or step == (len(tr_dl)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                    'Grad: {grad_norm:.4f}  '\n",
    "                    'LR: {lr:.8f}  '\n",
    "                    .format(epoch+1, step, len(tr_dl), \n",
    "                            loss=am,\n",
    "                            grad_norm=grad_norm,\n",
    "                            lr=scheduler.get_lr()[0]))\n",
    "            wandb.log({f\"[fold{fold}] loss\": am.val,\n",
    "                    f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "            \n",
    "            if (step + 1) % self.config.n_eval_steps == 0:\n",
    "                model.eval()\n",
    "                avg_vl_loss, predictions = self.infer(\n",
    "                    model, vl_dl, n_vl)\n",
    "                score, best_th = self.evaluate(\n",
    "                    predictions=predictions,\n",
    "                    valid_texts=valid_texts, \n",
    "                    valid_labels=valid_labels,\n",
    "                    th_range=self.config.th_range, \n",
    "                    th_step=self.config.th_step)\n",
    "                self.log({\n",
    "                    f'[fold{fold}] epoch': epoch+1,\n",
    "                    f'[fold{fold}] step': step,\n",
    "                    f'[fold{fold}] avg_val_loss': avg_vl_loss,\n",
    "                    f'[fold{fold}] score': score,\n",
    "                    f'[fold{fold}] best_th': best_th\n",
    "                })\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    self.save_ckpt(\n",
    "                        fold=fold, \n",
    "                        model=model, \n",
    "                        predictions=predictions)\n",
    "                model.train()\n",
    "                \n",
    "        return am.avg, best_score, samplewise_losses\n",
    "\n",
    "    \n",
    "    @inference_mode()\n",
    "    def infer(self, model:Module, vl_dl:DataLoader, n_vl:int) -> tuple:\n",
    "        \n",
    "        model.eval()\n",
    "        losses = AverageMeter()\n",
    "        preds = []\n",
    "        for inputs, labels in vl_dl:\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            batch_size = labels.size(0)\n",
    "            y_preds = model(inputs)\n",
    "            loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "            loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "            if self.config.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.config.gradient_accumulation_steps\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        predictions = np.concatenate(preds).reshape(\n",
    "            (n_vl, self.config.max_len)\n",
    "        )\n",
    "        \n",
    "        return losses.avg, predictions\n",
    "\n",
    "    \n",
    "    def create_dl(self, df:DataFrame, feature_text_max_len:int, pn_history_max_len:int, is_train:bool, seed:int) -> DataLoader:\n",
    "        \n",
    "        ds = TrainDataset(\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_len=self.config.max_len,\n",
    "            feature_text_max_len=feature_text_max_len,\n",
    "            pn_history_max_len=pn_history_max_len,\n",
    "            df=df)\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed+int(is_train))\n",
    "        \n",
    "        return DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.config.batch_size if is_train else self.config.batch_size * 2,\n",
    "            shuffle=is_train,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True, \n",
    "            drop_last=is_train,\n",
    "            generator=g\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def evaluate(self, predictions:ndarray, valid_texts:tuple, valid_labels:ndarray, th_range:list, th_step:float=0.005) -> tuple:\n",
    "        \n",
    "        char_probs = get_char_probs(\n",
    "            valid_texts, \n",
    "            predictions, \n",
    "            self.tokenizer)\n",
    "        best_score=-100\n",
    "        for th in np.arange(th_range[0], th_range[1], th_step):\n",
    "            th = np.round(th,4)\n",
    "            results = get_results(\n",
    "                char_probs, \n",
    "                valid_texts, \n",
    "                th=th\n",
    "            )\n",
    "            preds = get_predictions(results)\n",
    "            score = get_score(valid_labels, preds)\n",
    "            if best_score < score:\n",
    "                best_th=th\n",
    "                best_score=score\n",
    "        return best_score, best_th\n",
    "    \n",
    "    \n",
    "    def save_ckpt(self, fold:int, model:Module, predictions:ndarray) -> None:\n",
    "        \n",
    "        torch.save(\n",
    "            {'model': model.state_dict(),'predictions': predictions},\n",
    "            f'{self.config.output_dir}{self.config.ckpt_name}_fold{fold}_best.pth'\n",
    "        )\n",
    "        self.logger.info('model has been saved.')\n",
    "\n",
    "        \n",
    "    def compute_loss_th(self, samplewise_losses:list, fold:int, epoch:int) -> float:\n",
    "\n",
    "        mu_loss = np.mean(samplewise_losses)\n",
    "        std_loss = np.std(samplewise_losses)\n",
    "        loss_th = mu_loss+std_loss*self.config.n_loss_removal_std\n",
    "        joblib.dump(\n",
    "            value=samplewise_losses, \n",
    "            filename=f'samplewise_losses_f{fold}_e{epoch}.pkl', \n",
    "            compress=3)\n",
    "        \n",
    "        return loss_th\n",
    "    \n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        df:DataFrame,\n",
    "        pl_df:DataFrame,\n",
    "        feature_text_max_len:int, \n",
    "        pn_history_max_len:int) -> None:\n",
    "    \n",
    "        oof_df = pd.DataFrame()\n",
    "        for f in range(self.config.n_folds):\n",
    "            self.logger.info(f\"========== fold: {f} training ==========\")\n",
    "            \n",
    "            model = CustomModel(\n",
    "                model_name=self.config.model, \n",
    "                config_path=None, \n",
    "                pretrained=True).to(self.device)\n",
    "\n",
    "            tr_df = df[df['fold'] != f].reset_index(drop=True)\n",
    "            if self.config.pl_frac > 0.0:\n",
    "                tr_pl_df = pl_df.sample(frac=self.config.pl_frac, random_state=self.config.seed)\n",
    "                self.logger.info(f'{len(tr_pl_df)} pseudo labeled data was sampled.')\n",
    "                tr_df = pd.concat(\n",
    "                    (tr_df, tr_pl_df)\n",
    "                ).sample(frac=1.0, random_state=self.config.seed)\n",
    "            tr_dl = self.create_dl(\n",
    "                df=tr_df, \n",
    "                feature_text_max_len=feature_text_max_len, \n",
    "                pn_history_max_len=pn_history_max_len, \n",
    "                is_train=True,\n",
    "                seed=self.config.seed\n",
    "            )\n",
    "            num_train_steps = int(len(tr_df) / self.config.batch_size * self.config.epochs)\n",
    "            \n",
    "            vl_df = df[df['fold'] == f].reset_index(drop=True)\n",
    "            vl_dl = self.create_dl(\n",
    "                df=vl_df, \n",
    "                feature_text_max_len=feature_text_max_len, \n",
    "                pn_history_max_len=pn_history_max_len, \n",
    "                is_train=False,\n",
    "                seed=self.config.seed)\n",
    "            valid_texts = vl_df['pn_history'].to_numpy()\n",
    "            valid_labels = create_labels_for_scoring(vl_df)\n",
    "\n",
    "            optimizer_parameters = get_optimizer_params(\n",
    "                model,\n",
    "                encoder_lr=self.config.encoder_lr, \n",
    "                decoder_lr=self.config.decoder_lr,\n",
    "                weight_decay=self.config.weight_decay)\n",
    "            optimizer = AdamW(\n",
    "                optimizer_parameters, \n",
    "                lr=self.config.encoder_lr, \n",
    "                eps=self.config.eps, \n",
    "                betas=self.config.betas)\n",
    "            scheduler = get_scheduler(\n",
    "                scheduler=self.config.scheduler, \n",
    "                optimizer=optimizer, \n",
    "                num_warmup_steps=self.config.num_warmup_steps,\n",
    "                num_train_steps=num_train_steps,\n",
    "                num_cycles=self.config.num_cycles)\n",
    "            \n",
    "            best_score = 0\n",
    "            for epoch in range(self.config.epochs):\n",
    "\n",
    "                if epoch==self.config.loss_removal_start_ep:\n",
    "                    loss_th = self.compute_loss_th(\n",
    "                        samplewise_losses=samplewise_losses, \n",
    "                        fold=f, \n",
    "                        epoch=epoch)\n",
    "                    self.logger.info(f'Loss th: {loss_th}')\n",
    "                \n",
    "                avg_tr_loss, stepwise_best_score, samplewise_losses = self.train_with_eval(\n",
    "                    model,\n",
    "                    f, \n",
    "                    (tr_dl, vl_dl), \n",
    "                    optimizer, \n",
    "                    epoch, \n",
    "                    scheduler,\n",
    "                    loss_th if epoch>=self.config.loss_removal_start_ep else None,\n",
    "                    valid_texts,\n",
    "                    valid_labels,\n",
    "                    len(vl_df),\n",
    "                    best_score)\n",
    "                \n",
    "                avg_vl_loss, predictions = self.infer(\n",
    "                    model, vl_dl, len(vl_df))\n",
    "                score, best_th = self.evaluate(\n",
    "                    predictions=predictions,\n",
    "                    valid_texts=valid_texts, \n",
    "                    valid_labels=valid_labels,\n",
    "                    th_range=self.config.th_range, \n",
    "                    th_step=self.config.th_step)\n",
    "                \n",
    "                self.log({\n",
    "                    f\"[fold{f}] epoch\": epoch+1, \n",
    "                    f\"[fold{f}] avg_train_loss\": avg_tr_loss, \n",
    "                    f\"[fold{f}] avg_val_loss\": avg_vl_loss,\n",
    "                    f\"[fold{f}] score\": score,\n",
    "                    f\"[fold{f}] best_th\": best_th})\n",
    "                \n",
    "                if score > stepwise_best_score:\n",
    "                    best_score = score\n",
    "                    self.save_ckpt(\n",
    "                        fold=f, \n",
    "                        model=model, \n",
    "                        predictions=predictions)\n",
    "\n",
    "            predictions = torch.load(\n",
    "                f'{self.config.output_dir}{self.config.ckpt_name}_fold{f}_best.pth', \n",
    "                map_location=torch.device('cpu'))['predictions']\n",
    "            vl_df[[i for i in range(self.config.max_len)]] = predictions\n",
    "            oof_df = pd.concat([oof_df, vl_df])\n",
    "            \n",
    "            self.logger.info(f\"========== fold: {f} result ==========\")\n",
    "            \n",
    "            score, th = get_result(vl_df, self.tokenizer, self.config.max_len)\n",
    "            self.log({\n",
    "                f\"[fold{f}] overall score\": score,\n",
    "                f\"[fold{f}] overall best th\": th\n",
    "            })\n",
    "            oof_df.to_pickle(f'{self.config.output_dir}oof_df_fold{f}.pkl')\n",
    "        \n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        self.logger.info(f\"========== CV ==========\")\n",
    "        score, th = get_result(oof_df, self.tokenizer, self.config.max_len)\n",
    "        self.log({\n",
    "            f\"overall score\": score,\n",
    "            f\"overall best th\": th\n",
    "        })\n",
    "        oof_df.to_pickle(self.config.output_dir+'oof_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "executionInfo": {
     "elapsed": 226790,
     "status": "error",
     "timestamp": 1651312074514,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "db38bc60",
    "outputId": "17705e20-a2c2-4205-bb80-5f45fad323fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Some weights of the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "188067 pseudo labeled data was sampled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/24849] Loss: 3.5834(3.5834) Grad: inf  LR: 0.00002500  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1000/24849] Loss: 0.0094(0.0440) Grad: 921.2812  LR: 0.00002500  \n",
      "Epoch: [1][2000/24849] Loss: 0.0008(0.0267) Grad: 207.7176  LR: 0.00002499  \n",
      "Epoch: [1][3000/24849] Loss: 0.0023(0.0200) Grad: 854.3605  LR: 0.00002498  \n",
      "Epoch: [1][4000/24849] Loss: 0.0003(0.0166) Grad: 156.5569  LR: 0.00002496  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 4999 Avg_val_loss: 0.01416611923699404 Score: 0.8873386961622255 Best_th: 0.485\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5000/24849] Loss: 0.0022(0.0144) Grad: 720.0128  LR: 0.00002493  \n",
      "Epoch: [1][6000/24849] Loss: 0.0070(0.0129) Grad: 3533.6841  LR: 0.00002490  \n",
      "Epoch: [1][7000/24849] Loss: 0.0001(0.0118) Grad: 370.2377  LR: 0.00002486  \n",
      "Epoch: [1][8000/24849] Loss: 0.0000(0.0110) Grad: 130.2960  LR: 0.00002482  \n",
      "Epoch: [1][9000/24849] Loss: 0.0033(0.0103) Grad: 2018.7012  LR: 0.00002478  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 9999 Avg_val_loss: 0.01603452535325798 Score: 0.8955114593248884 Best_th: 0.435\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][10000/24849] Loss: 0.0001(0.0098) Grad: 371.8748  LR: 0.00002472  \n",
      "Epoch: [1][11000/24849] Loss: 0.0010(0.0094) Grad: 4178.8623  LR: 0.00002467  \n",
      "Epoch: [1][12000/24849] Loss: 0.0003(0.0090) Grad: 1990.8484  LR: 0.00002460  \n",
      "Epoch: [1][13000/24849] Loss: 0.0007(0.0087) Grad: 3694.0203  LR: 0.00002453  \n",
      "Epoch: [1][14000/24849] Loss: 0.0119(0.0085) Grad: 21227.4395  LR: 0.00002446  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 14999 Avg_val_loss: 0.01619316376563344 Score: 0.9026162638284486 Best_th: 0.415\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][15000/24849] Loss: 0.0001(0.0082) Grad: 1618.3350  LR: 0.00002438  \n",
      "Epoch: [1][16000/24849] Loss: 0.0092(0.0080) Grad: 59670.5820  LR: 0.00002430  \n",
      "Epoch: [1][17000/24849] Loss: 0.0000(0.0078) Grad: 73.1968  LR: 0.00002421  \n",
      "Epoch: [1][18000/24849] Loss: 0.0031(0.0077) Grad: 3821.2307  LR: 0.00002411  \n",
      "Epoch: [1][19000/24849] Loss: 0.0024(0.0076) Grad: 1924.6848  LR: 0.00002401  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 19999 Avg_val_loss: 0.016277396699989222 Score: 0.9022562659580011 Best_th: 0.455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][20000/24849] Loss: 0.0026(0.0075) Grad: 32877.4531  LR: 0.00002391  \n",
      "Epoch: [1][21000/24849] Loss: 0.0210(0.0073) Grad: 51495.1992  LR: 0.00002380  \n",
      "Epoch: [1][22000/24849] Loss: 0.0005(0.0072) Grad: 2013.5266  LR: 0.00002368  \n",
      "Epoch: [1][23000/24849] Loss: 0.0017(0.0071) Grad: 3548.5576  LR: 0.00002356  \n",
      "Epoch: [1][24000/24849] Loss: 0.0030(0.0070) Grad: 5690.6265  LR: 0.00002344  \n",
      "Epoch: [1][24848/24849] Loss: 0.0202(0.0069) Grad: 144700.8906  LR: 0.00002333  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Avg_train_loss: 0.006919411244336401 Avg_val_loss: 0.016859391303851036 Score: 0.9018132918706532 Best_th: 0.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/24849] Loss: 0.0017(0.0017) Grad: 7212.7568  LR: 0.00002333  \n",
      "Epoch: [2][1000/24849] Loss: 0.0133(0.0035) Grad: 23871.6172  LR: 0.00002319  \n",
      "Epoch: [2][2000/24849] Loss: 0.0000(0.0036) Grad: 193.0016  LR: 0.00002305  \n",
      "Epoch: [2][3000/24849] Loss: 0.0005(0.0037) Grad: 10803.9248  LR: 0.00002291  \n",
      "Epoch: [2][4000/24849] Loss: 0.0014(0.0038) Grad: 11847.9121  LR: 0.00002276  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "Epoch: 2 Step: 4999 Avg_val_loss: 0.015640974589757835 Score: 0.902644592114948 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5000/24849] Loss: 0.0034(0.0038) Grad: 7794.6597  LR: 0.00002261  \n",
      "Epoch: [2][6000/24849] Loss: 0.0002(0.0039) Grad: 393.2673  LR: 0.00002245  \n",
      "Epoch: [2][7000/24849] Loss: 0.0088(0.0039) Grad: 17423.3066  LR: 0.00002229  \n",
      "Epoch: [2][8000/24849] Loss: 0.0057(0.0040) Grad: 3092.7561  LR: 0.00002212  \n",
      "Epoch: [2][9000/24849] Loss: 0.0009(0.0041) Grad: 432.1192  LR: 0.00002195  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Step: 9999 Avg_val_loss: 0.012709421794047462 Score: 0.9067027395421361 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][10000/24849] Loss: 0.0025(0.0041) Grad: 6600.7510  LR: 0.00002178  \n",
      "Epoch: [2][11000/24849] Loss: 0.0023(0.0041) Grad: 3336.7642  LR: 0.00002160  \n",
      "Epoch: [2][12000/24849] Loss: 0.0440(0.0041) Grad: 34395.1680  LR: 0.00002142  \n",
      "Epoch: [2][13000/24849] Loss: 0.0109(0.0042) Grad: 3736.4089  LR: 0.00002123  \n",
      "Epoch: [2][14000/24849] Loss: 0.0039(0.0042) Grad: 8221.7305  LR: 0.00002104  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Step: 14999 Avg_val_loss: 0.012916624960212779 Score: 0.9048987154664501 Best_th: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][15000/24849] Loss: 0.0022(0.0041) Grad: 1084.0457  LR: 0.00002085  \n",
      "Epoch: [2][16000/24849] Loss: 0.0000(0.0041) Grad: 27.7564  LR: 0.00002065  \n",
      "Epoch: [2][17000/24849] Loss: 0.0024(0.0041) Grad: 4636.9243  LR: 0.00002045  \n",
      "Epoch: [2][18000/24849] Loss: 0.0023(0.0040) Grad: 39991.2305  LR: 0.00002024  \n",
      "Epoch: [2][19000/24849] Loss: 0.0001(0.0040) Grad: 610.5678  LR: 0.00002003  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Step: 19999 Avg_val_loss: 0.017184235237097577 Score: 0.9062256849705885 Best_th: 0.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][20000/24849] Loss: 0.0000(0.0040) Grad: 11.5343  LR: 0.00001982  \n",
      "Epoch: [2][21000/24849] Loss: 0.0001(0.0040) Grad: 1174.5222  LR: 0.00001961  \n",
      "Epoch: [2][22000/24849] Loss: 0.0000(0.0040) Grad: 58.4675  LR: 0.00001939  \n",
      "Epoch: [2][23000/24849] Loss: 0.0000(0.0039) Grad: 300.6627  LR: 0.00001917  \n",
      "Epoch: [2][24000/24849] Loss: 0.0017(0.0039) Grad: 9308.6484  LR: 0.00001894  \n",
      "Epoch: [2][24848/24849] Loss: 0.0035(0.0039) Grad: 30648.2285  LR: 0.00001875  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Avg_train_loss: 0.0039053113784273076 Avg_val_loss: 0.017486309201232324 Score: 0.9102101508802214 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/24849] Loss: 0.0012(0.0012) Grad: 8683.6357  LR: 0.00001875  \n",
      "Epoch: [3][1000/24849] Loss: 0.0129(0.0029) Grad: 26464.3125  LR: 0.00001852  \n",
      "Epoch: [3][2000/24849] Loss: 0.0003(0.0029) Grad: 974.2806  LR: 0.00001829  \n",
      "Epoch: [3][3000/24849] Loss: 0.0035(0.0030) Grad: 25950.0977  LR: 0.00001805  \n",
      "Epoch: [3][4000/24849] Loss: 0.0014(0.0030) Grad: 4348.4438  LR: 0.00001782  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Step: 4999 Avg_val_loss: 0.016036911406497295 Score: 0.909707222802104 Best_th: 0.415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5000/24849] Loss: 0.0030(0.0031) Grad: 3798.6440  LR: 0.00001758  \n",
      "Epoch: [3][6000/24849] Loss: 0.0032(0.0030) Grad: 18957.6133  LR: 0.00001733  \n",
      "Epoch: [3][7000/24849] Loss: 0.0017(0.0030) Grad: 11356.8604  LR: 0.00001709  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][8000/24849] Loss: 0.0036(0.0030) Grad: 7986.9092  LR: 0.00001684  \n",
      "Epoch: [3][9000/24849] Loss: 0.0000(0.0030) Grad: 69.2264  LR: 0.00001660  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1301/2202288625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     logger=logger)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m trainer.run(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpl_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpl_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1301/2015553609.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, df, pl_df, feature_text_max_len, pn_history_max_len)\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss th: {loss_th}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                 avg_tr_loss, stepwise_best_score, samplewise_losses = self.train_with_eval(\n\u001b[0m\u001b[1;32m    376\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1301/2015553609.py\u001b[0m in \u001b[0;36mtrain_with_eval\u001b[0;34m(self, model, fold, dls, optimizer, epoch, scheduler, loss_th, valid_texts, valid_labels, n_vl, best_score)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 avg_vl_loss, predictions = self.infer(\n\u001b[1;32m    190\u001b[0m                     model, vl_dl, n_vl)\n\u001b[0;32m--> 191\u001b[0;31m                 score, best_th = self.evaluate(\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mvalid_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1301/2015553609.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, predictions, valid_texts, valid_labels, th_range, th_step)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             results = get_results(\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0mchar_probs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mvalid_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1301/2305902888.py\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(char_probs, pn_histories, th)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;31m# 最後の2文字が\\n-の場合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mtarget_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustered_pos_char_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtarget_idx\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpn_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtarget_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'\\n-'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mclustered_pos_char_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustered_pos_char_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    logger=logger)\n",
    "\n",
    "trainer.run(\n",
    "    df=df_train,\n",
    "    pl_df=pl_train,\n",
    "    feature_text_max_len=feature_text_max_len, \n",
    "    pn_history_max_len=pn_history_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1651312074512,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f5a96081-3aa7-4948-be95-67e31d3bd7e6"
   },
   "outputs": [],
   "source": [
    "commit_msg = '\"run_name: ' + wandb.run.name[:wandb.run.name.rfind('-')] + '\"'\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1651312074513,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "a8ac591e"
   },
   "outputs": [],
   "source": [
    "# !git add baseline-train.ipynb\n",
    "# !git add ../input/raiii-nbme/config.yml\n",
    "# !git commit -m $commit_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1651312074513,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f9EURHdaqV15"
   },
   "outputs": [],
   "source": [
    "12.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1651312074514,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "sFN1cCF8zcK4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00adb1f99dc140b4a293e96d77485bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0da24853130543829a39f79ab1fadcd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbccff640fa3407bb8ae2a2c1f40afe2",
      "placeholder": "​",
      "style": "IPY_MODEL_44aa0c7a57fc429aa7fa7faa7a0e9eaa",
      "value": "Downloading: 100%"
     }
    },
    "138066817ded4fa69b551f5f348d64d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41f47ec442474719936603b59d907c65",
      "placeholder": "​",
      "style": "IPY_MODEL_ab79ac7e7d4347d4b7f5532338e155fc",
      "value": " 482/482 [00:00&lt;00:00, 4.01kB/s]"
     }
    },
    "1b50897e46d74bf0977a0218c424f596": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4215a5ca45ce4d368cbf69610e39b499",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e308a1e284024d48bf2ec05ce08ac860",
      "value": 1355863
     }
    },
    "1fd0b6fc0fae481991b0ab4503a0b755": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec6dd9f7b1e849bab372cb5df4b93531",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f40caab4b1e4310935b17be7b5a4e93",
      "value": 898823
     }
    },
    "24cf07e1a7c443259917d487a83cb32b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30b2afa7062b47fab7587476a6eca617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bae1237788084a8d866042ed69d2293c",
      "placeholder": "​",
      "style": "IPY_MODEL_5373c537d30f41aba39af4334ecf6f36",
      "value": "Downloading: 100%"
     }
    },
    "3d51c94c20ad4c83bc27023439d60d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24cf07e1a7c443259917d487a83cb32b",
      "placeholder": "​",
      "style": "IPY_MODEL_a674d7856b3646d4b58736cd6da06412",
      "value": "Downloading: 100%"
     }
    },
    "3dfd6ffec9b24babadfec07ae9b4d4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46e47f4bb99a40d18aa19d5363d705d7",
       "IPY_MODEL_c4b736fcb0e848aa9c4af1acd87fc245",
       "IPY_MODEL_138066817ded4fa69b551f5f348d64d3"
      ],
      "layout": "IPY_MODEL_51a576ced81f4db398a59c17ee4ed72a"
     }
    },
    "41f47ec442474719936603b59d907c65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4215a5ca45ce4d368cbf69610e39b499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44aa0c7a57fc429aa7fa7faa7a0e9eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46e47f4bb99a40d18aa19d5363d705d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e5730dbbedc453084d26fce77c8f11a",
      "placeholder": "​",
      "style": "IPY_MODEL_c8cdc3e86a9a45dc9d793c3af5c2b200",
      "value": "Downloading: 100%"
     }
    },
    "4f40caab4b1e4310935b17be7b5a4e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51a576ced81f4db398a59c17ee4ed72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5373c537d30f41aba39af4334ecf6f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5da8d5ce32994a09bf936227fa5edd12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30b2afa7062b47fab7587476a6eca617",
       "IPY_MODEL_1fd0b6fc0fae481991b0ab4503a0b755",
       "IPY_MODEL_845a7583cf5c41cca875cb882249410d"
      ],
      "layout": "IPY_MODEL_c171770408b142d5b1226b47d46d1f01"
     }
    },
    "6575cc7a10f4437aa7d11fa7ceca4763": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67a2c064710d4776931e123353ae4d7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68f2c6ede37445a09e0e3f9445cfd187": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d51c94c20ad4c83bc27023439d60d91",
       "IPY_MODEL_1b50897e46d74bf0977a0218c424f596",
       "IPY_MODEL_869542edce0442c8898a0717f9ff4a85"
      ],
      "layout": "IPY_MODEL_cec4f5657c3241eeb6d8ba7ec0efb5ef"
     }
    },
    "6cb0890136fe43869dfa504840a6cdf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73ab2df54724494ba033d8b01b517392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "800add5dca784b57af4947833d6a9eef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "845a7583cf5c41cca875cb882249410d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a4d42eeb4a4bd999d74f88e20e13f6",
      "placeholder": "​",
      "style": "IPY_MODEL_940111d655744355b867729c5edeabcf",
      "value": " 878k/878k [00:00&lt;00:00, 2.68MB/s]"
     }
    },
    "869542edce0442c8898a0717f9ff4a85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcbd2f47603a4a9fa5bdd7720992d5b2",
      "placeholder": "​",
      "style": "IPY_MODEL_e4367b4d96424071be69a99e544b9727",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 1.88MB/s]"
     }
    },
    "940111d655744355b867729c5edeabcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99a4d42eeb4a4bd999d74f88e20e13f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e5730dbbedc453084d26fce77c8f11a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a674d7856b3646d4b58736cd6da06412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab79ac7e7d4347d4b7f5532338e155fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b696976706ad4bc2a969cb9e15a82eb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bae1237788084a8d866042ed69d2293c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c171770408b142d5b1226b47d46d1f01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b736fcb0e848aa9c4af1acd87fc245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6575cc7a10f4437aa7d11fa7ceca4763",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67a2c064710d4776931e123353ae4d7c",
      "value": 482
     }
    },
    "c8cdc3e86a9a45dc9d793c3af5c2b200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cec4f5657c3241eeb6d8ba7ec0efb5ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de995a2f649e4cef8c85187aeba4cd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0da24853130543829a39f79ab1fadcd1",
       "IPY_MODEL_fbb2db51a41c4a4686709c9f01e6955f",
       "IPY_MODEL_f911ea9470da45c5883a305e92b9787e"
      ],
      "layout": "IPY_MODEL_73ab2df54724494ba033d8b01b517392"
     }
    },
    "e308a1e284024d48bf2ec05ce08ac860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4367b4d96424071be69a99e544b9727": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec6dd9f7b1e849bab372cb5df4b93531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f911ea9470da45c5883a305e92b9787e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b696976706ad4bc2a969cb9e15a82eb7",
      "placeholder": "​",
      "style": "IPY_MODEL_00adb1f99dc140b4a293e96d77485bbe",
      "value": " 446k/446k [00:00&lt;00:00, 719kB/s]"
     }
    },
    "fbb2db51a41c4a4686709c9f01e6955f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_800add5dca784b57af4947833d6a9eef",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cb0890136fe43869dfa504840a6cdf8",
      "value": 456318
     }
    },
    "fbccff640fa3407bb8ae2a2c1f40afe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcbd2f47603a4a9fa5bdd7720992d5b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
