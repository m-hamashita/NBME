{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1651311680734,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "Ic8N2I-_AuR_",
    "outputId": "134f23b1-2c94-4be2-8d43-47de93807785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  1 06:21:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   45C    P0    65W / 350W |      0MiB / 40536MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM...  Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   38C    P0    58W / 350W |      0MiB / 40536MiB |     21%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.yml\r\n",
      "deberta-v2-3-fast-tokenizer\r\n",
      "features.csv\r\n",
      "nbme-score-clinical-patient-notes.zip\r\n",
      "patient_notes.csv\r\n",
      "roberta-large-self-supervised-learning-9epoch\r\n",
      "roberta-large-self-supervised-learning-9epoch.zip\r\n",
      "sample_submission.csv\r\n",
      "test.csv\r\n",
      "train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16301,
     "status": "ok",
     "timestamp": 1651311697288,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "7GP9_WE_qfhx",
    "outputId": "7f9bb416-a185-4efb-acbf-bd38771ccfb1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1651311723025,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "UIbnuTIAqbcP"
   },
   "outputs": [],
   "source": [
    "# # colab用設定\n",
    "# # もしcolab上だったら実行するものを以下のif文で指定する\n",
    "# import sys\n",
    "# # Colaboratory環境ならTrue\n",
    "# is_colab='google.colab' in sys.modules\n",
    "# # Kaggle Notebook環境ならTrue\n",
    "# is_kaggle='kaggle_web_client' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61062,
     "status": "ok",
     "timestamp": 1651311784637,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "TDnZasm0v_Ww",
    "outputId": "be61105e-8e11-4c9c-d203-8ef7e34a5eca"
   },
   "outputs": [],
   "source": [
    "# if is_colab:\n",
    "#     # from google.colab import drive\n",
    "#     # drive.mount('/content/drive')\n",
    "#     # install pakages\n",
    "#     ! apt install -qq vim fish htop tree\n",
    "#     ! ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi #デフォのnvidia-smiがぶっ壊れてる\n",
    "#     # fileの移し替え\n",
    "#     !cp -r /content/drive/MyDrive/dotfiles_for_colab/.vscode/ /content/\n",
    "#     !mkdir /root/.kaggle/\n",
    "#     !cp /content/drive/MyDrive/dotfiles_for_colab/kaggle.json /root/.kaggle/kaggle.json\n",
    "#     !chmod 600 ~/.kaggle/kaggle.json\n",
    "#     !kaggle competitions download -c nbme-score-clinical-patient-notes -p /content/input/nbme-score-clinical-patient-notes/\n",
    "#     !unzip /content/input/nbme-score-clinical-patient-notes/nbme-score-clinical-patient-notes.zip -d /content/input/nbme-score-clinical-patient-notes/\n",
    "#     !rm /content/input/nbme-score-clinical-patient-notes/nbme-score-clinical-patient-notes.zip\n",
    "#     # kaggleからデータのダウンロード\n",
    "#     !kaggle datasets download -d nbroad/deberta-v2-3-fast-tokenizer -p /content/input/deberta-v2-3-fast-tokenizer/\n",
    "#     !unzip /content/input/deberta-v2-3-fast-tokenizer/deberta-v2-3-fast-tokenizer.zip -d /content/input/deberta-v2-3-fast-tokenizer/\n",
    "#     !rm /content/input/deberta-v2-3-fast-tokenizer/deberta-v2-3-fast-tokenizer.zip\n",
    "# !kaggle datasets download -d mpeg31/roberta-large-self-supervised-learning-9epoch -p ../input\n",
    "# !unzip ../input/roberta-large-self-supervised-learning-9epoch.zip -d ../input/roberta-large-self-supervised-learning-9epoch/\n",
    "    \n",
    "#     # pip install\n",
    "#     !pip install -q transformers wandb sentencepiece\n",
    "#     !mkdir /content/notebook\n",
    "#     !cp /content/drive/MyDrive/exp093/pl_train.csv /content/input/\n",
    "#     #作業用directoryの移動\n",
    "#     %cd /content/notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651311784637,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "I35xIFQiv1xD",
    "outputId": "3b714204-8c21-4c56-cfc1-9ec6509352f6"
   },
   "outputs": [],
   "source": [
    "# %cd /content/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7426d7d"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3148,
     "status": "ok",
     "timestamp": 1651311787780,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "797404f7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.core.display import display\n",
    "import random\n",
    "import re\n",
    "import yaml\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import torch\n",
    "from logging import Logger, getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "import wandb\n",
    "from wandb.sdk.wandb_config import Config\n",
    "\n",
    "\n",
    "def init_pandas() -> None:\n",
    "\n",
    "    pd.set_option(\"display.max_rows\", 500)\n",
    "    pd.set_option(\"display.max_columns\", 500)\n",
    "    pd.set_option(\"display.width\", 1000)\n",
    "\n",
    "\n",
    "def get_logger(filename: str) -> Logger:\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 42) -> None:\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def init_wandb(wandb_key: str) -> Config:\n",
    "\n",
    "    # from kaggle_secrets import UserSecretsClient\n",
    "    # user_secrets = UserSecretsClient()\n",
    "    secret_value_0 = wandb_key\n",
    "    wandb.login(key=secret_value_0)\n",
    "\n",
    "#     my_ds_path = \"../input\"\n",
    "    loader = yaml.SafeLoader\n",
    "    loader.add_implicit_resolver(\n",
    "        \"tag:yaml.org,2002:float\",\n",
    "        re.compile(\n",
    "            \"\"\"^(?:\n",
    "         [-+]?(?:[0-9][0-9_]*)\\\\.[0-9_]*(?:[eE][-+]?[0-9]+)?\n",
    "        |[-+]?(?:[0-9][0-9_]*)(?:[eE][-+]?[0-9]+)\n",
    "        |\\\\.[0-9_]+(?:[eE][-+][0-9]+)?\n",
    "        |[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\\\.[0-9_]*\n",
    "        |[-+]?\\\\.(?:inf|Inf|INF)\n",
    "        |\\\\.(?:nan|NaN|NAN))$\"\"\",\n",
    "            re.X,\n",
    "        ),\n",
    "        list(\"-+0123456789.\"),\n",
    "    )\n",
    "    with open(f\"./config.yml\") as f:\n",
    "        param = yaml.load(f, Loader=loader)\n",
    "    wandb.init(project=param[\"project\"], config=param)\n",
    "    wandb.config.update(param)\n",
    "    print(f\"run name: {wandb.run.name}\")\n",
    "    return wandb.config\n",
    "\n",
    "\n",
    "def mk_output_dir(path: str) -> None:\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 6408,
     "status": "ok",
     "timestamp": 1651311794183,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "383q4PFUrZKP",
    "outputId": "e7a23b96-dde6-4df8-8acf-91f92a64646b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmpeg\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tmp/workspace/NBME/exp093/wandb/run-20220501_062121-2vb1fnc6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mpeg/NBME-ScoreClinicalPatientNotes/runs/2vb1fnc6\" target=\"_blank\">rose-thunder-31</a></strong> to <a href=\"https://wandb.ai/mpeg/NBME-ScoreClinicalPatientNotes\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run name: rose-thunder-31\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from getpass import getpass\n",
    "\n",
    "# if is_kaggle:\n",
    "#     from kaggle_secrets import UserSecretsClient\n",
    "#     user_secrets = UserSecretsClient()\n",
    "#     secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "# elif is_colab:\n",
    "#     with open('/content/drive/MyDrive/dotfiles_for_colab/wandb_api.txt') as f:\n",
    "#         secret_value_0=f.readline()\n",
    "# else:\n",
    "#     raise ValueError()\n",
    "\n",
    "\n",
    "wandb_key = getpass()\n",
    "config = init_wandb(wandb_key=wandb_key)\n",
    "mk_output_dir(path=config.output_dir)\n",
    "logger = get_logger(\n",
    "    filename=config.output_dir+'train'\n",
    ")\n",
    "seed_everything(seed=config.seed)\n",
    "init_pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "575ae408"
   },
   "source": [
    "# Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1651311794987,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "8771dcad"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "def get_score(y_true:ndarray, y_pred:ndarray) -> float:\n",
    "\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def micro_f1(preds:list, truths:list) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    \n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans:list, length=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "        \n",
    "    return micro_f1(bin_preds, bin_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4675,
     "status": "ok",
     "timestamp": 1651311799657,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "c20fdb1b"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from numpy import ndarray\n",
    "from pandas import DataFrame\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "\n",
    "def create_labels_for_scoring(df:DataFrame):\n",
    "\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    \n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts:list, predictions:ndarray, tokenizer:PreTrainedTokenizer) -> list:\n",
    "    \n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        prev_pred = 0\n",
    "        prev_end = -1\n",
    "        for offset_mapping, pred in zip(encoded['offset_mapping'], prediction):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "            if start != prev_end:\n",
    "                results[i][prev_end:start] = (pred+prev_pred)/2\n",
    "            prev_pred = pred\n",
    "            prev_end = end\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def cluster_elements(xs:list) -> list:\n",
    "\n",
    "    clusters = [[]]\n",
    "    \n",
    "    if len(xs) == 0:\n",
    "        return clusters\n",
    "\n",
    "    prev_x = xs[0]-1\n",
    "    for x in xs:\n",
    "        if x == prev_x+1:\n",
    "            clusters[-1].append(x)\n",
    "        else:\n",
    "            clusters.append([x])\n",
    "        prev_x = x\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "\n",
    "def get_results(char_probs:list, pn_histories:list, th:float=0.5) -> list:\n",
    "    \n",
    "    label_strs = []\n",
    "    for char_prob, pn_history in zip(char_probs, pn_histories):\n",
    "        pos_char_indices = np.where(char_prob>th)[0] + 1\n",
    "        if len(pos_char_indices)>0 and pos_char_indices[0]==1:\n",
    "            pos_char_indices=np.hstack([[0],pos_char_indices])\n",
    "        clustered_pos_char_indices = cluster_elements(xs=pos_char_indices)\n",
    "        \n",
    "        for i in range(len(clustered_pos_char_indices)):\n",
    "            # 1文字目がspaceの場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                target_idx = clustered_pos_char_indices[i][0]-1\n",
    "                if target_idx>-1 and pn_history[target_idx] != ' ':\n",
    "                    clustered_pos_char_indices[i] = np.hstack([\n",
    "                        [target_idx],\n",
    "                        clustered_pos_char_indices[i]\n",
    "                    ])\n",
    "\n",
    "            # 1文字目が\\r\\nの場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                if clustered_pos_char_indices[i][0] > 0 and clustered_pos_char_indices[i][0]+2 < len(pn_history):\n",
    "                    if pn_history[clustered_pos_char_indices[i][0]:clustered_pos_char_indices[i][0]+2] == '\\r\\n':\n",
    "                        clustered_pos_char_indices[i] = clustered_pos_char_indices[i][2:]\n",
    "\n",
    "            # 最後の2文字が\\n-の場合\n",
    "            if len(clustered_pos_char_indices[i]) > 0:\n",
    "                target_idx = clustered_pos_char_indices[i][-1]-2\n",
    "                if target_idx>0 and pn_history[target_idx:target_idx+2]=='\\n-':\n",
    "                    clustered_pos_char_indices[i] = clustered_pos_char_indices[i][:-2]\n",
    "                \n",
    "                # yof対応\n",
    "#                 if len(clustered_pos_char_indices[i]) > 0:\n",
    "#                     target_idx = clustered_pos_char_indices[i][0]-1\n",
    "#                     if target_idx>-1 and len(clustered_pos_char_indices[i])>1 and (pn_history[target_idx:target_idx+3] in ['yof', 'YOF']):\n",
    "#                         clustered_pos_char_indices[i] = clustered_pos_char_indices[i][1:]\n",
    "\n",
    "#                     target_idx = clustered_pos_char_indices[i][-1]-3\n",
    "#                     if target_idx>-1 and len(clustered_pos_char_indices[i])>1 and (pn_history[target_idx:target_idx+3] in ['yof', 'YOF']):\n",
    "#                         clustered_pos_char_indices[i] = clustered_pos_char_indices[i][:-1]\n",
    "\n",
    "#                     if len(clustered_pos_char_indices[i])>0 and clustered_pos_char_indices[i][0]==clustered_pos_char_indices[i][-1]:\n",
    "#                         clustered_pos_char_indices[i] = np.hstack(\n",
    "#                             [\n",
    "#                                 clustered_pos_char_indices[i],\n",
    "#                                 [clustered_pos_char_indices[i][-1]+1]\n",
    "#                             ]\n",
    "#                         )\n",
    "\t\t\n",
    "        pos_char_spans = []\n",
    "        if len(clustered_pos_char_indices[0]) != 0:\n",
    "            for x in clustered_pos_char_indices:\n",
    "                if len(x)>0:\n",
    "                    pos_char_spans.append(\n",
    "                        [x[0],x[-1]]\n",
    "                    )\n",
    "        label_strs.append(\n",
    "            ';'.join([\n",
    "                f'{x[0]} {x[1]}' for x in pos_char_spans\n",
    "            ])\n",
    "        )\n",
    "    \n",
    "    return label_strs\n",
    "\n",
    "\n",
    "def get_predictions(results:list) -> list:\n",
    "    \n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_result(df_oof:DataFrame, tokenizer:PreTrainedTokenizer, max_len:int) -> tuple:\n",
    "\n",
    "    labels = create_labels_for_scoring(df_oof)\n",
    "    predictions = df_oof[[i for i in range(max_len)]].to_numpy()\n",
    "    char_probs = get_char_probs(df_oof['pn_history'].to_numpy(), predictions, tokenizer)\n",
    "    pn_histories = df_oof['pn_history'].to_list()\n",
    "    \n",
    "    score=-100\n",
    "    for th in np.arange(0.3,0.7,0.005):\n",
    "        th = np.round(th,4)\n",
    "        results = get_results(char_probs, pn_histories, th=th)\n",
    "        preds = get_predictions(results)\n",
    "        tmp_score = get_score(labels, preds)\n",
    "        if tmp_score > score:\n",
    "            best_th=th\n",
    "            score=tmp_score\n",
    "    \n",
    "    return score, best_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dc99c98"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-26T23:46:53.45023Z",
     "iopub.status.busy": "2022-04-26T23:46:53.449418Z",
     "iopub.status.idle": "2022-04-26T23:46:53.467497Z",
     "shell.execute_reply": "2022-04-26T23:46:53.466841Z",
     "shell.execute_reply.started": "2022-04-26T23:46:53.450185Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651311799657,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "PIvUkG_MqV10"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_features(features:DataFrame) -> None:\n",
    "    \n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1651311800787,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f93fc583",
    "outputId": "d4bc8fd6-65d7-42ce-ae34-c111a9500195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (14300, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (143, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>feature_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Chest-pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Lightheaded</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_num  case_num                                       feature_text\n",
       "0            0         0  Family-history-of-MI-OR-Family-history-of-myoc...\n",
       "1            1         0                 Family-history-of-thyroid-disorder\n",
       "2            2         0                                     Chest-pressure\n",
       "3            3         0                              Intermittent-symptoms\n",
       "4            4         0                                        Lightheaded"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_notes.shape: (42146, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pn_num</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17-year-old male, has come to the student heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17 yo male with recurrent palpitations for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Dillon Cleveland is a 17 y.o. male patient wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>a 17 yo m c/o palpitation started 3 mos ago; \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17yo male with no pmh here for evaluation of p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pn_num  case_num                                         pn_history\n",
       "0       0         0  17-year-old male, has come to the student heal...\n",
       "1       1         0  17 yo male with recurrent palpitations for the...\n",
       "2       2         0  Dillon Cleveland is a 17 y.o. male patient wit...\n",
       "3       3         0  a 17 yo m c/o palpitation started 3 mos ago; \\...\n",
       "4       4         0  17yo male with no pmh here for evaluation of p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_train['annotation'] = df_train['annotation'].map(lambda x: ast.literal_eval(x))\n",
    "df_train['location'] = df_train['location'].map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "features = pd.read_csv('../input/features.csv')\n",
    "preprocess_features(features)\n",
    "\n",
    "patient_notes = pd.read_csv('../input/patient_notes.csv')\n",
    "\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "display(df_train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "display(patient_notes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1651311800788,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ce0adc5c",
    "outputId": "b12f7852-3842-42c8-c03d-84ed6233c3d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00016_000</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>[dad with recent heart attcak]</td>\n",
       "      <td>[696 724]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00016_001</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[mom with \"thyroid disease]</td>\n",
       "      <td>[668 693]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00016_002</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>[chest pressure]</td>\n",
       "      <td>[203 217]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00016_003</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>[intermittent episodes, episode]</td>\n",
       "      <td>[70 91, 176 183]</td>\n",
       "      <td>Intermittent-symptoms</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00016_004</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>[felt as if he were going to pass out]</td>\n",
       "      <td>[222 258]</td>\n",
       "      <td>Lightheaded</td>\n",
       "      <td>HPI: 17yo M presents with palpitations. Patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  case_num  pn_num  feature_num                              annotation          location                                       feature_text                                         pn_history\n",
       "0  00016_000         0      16            0          [dad with recent heart attcak]         [696 724]  Family-history-of-MI-OR-Family-history-of-myoc...  HPI: 17yo M presents with palpitations. Patien...\n",
       "1  00016_001         0      16            1             [mom with \"thyroid disease]         [668 693]                 Family-history-of-thyroid-disorder  HPI: 17yo M presents with palpitations. Patien...\n",
       "2  00016_002         0      16            2                        [chest pressure]         [203 217]                                     Chest-pressure  HPI: 17yo M presents with palpitations. Patien...\n",
       "3  00016_003         0      16            3        [intermittent episodes, episode]  [70 91, 176 183]                              Intermittent-symptoms  HPI: 17yo M presents with palpitations. Patien...\n",
       "4  00016_004         0      16            4  [felt as if he were going to pass out]         [222 258]                                        Lightheaded  HPI: 17yo M presents with palpitations. Patien..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = df_train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "df_train = df_train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1651311801176,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "66337109"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def correct_annotation(df_train:DataFrame) -> None:\n",
    "    df_train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n",
    "    df_train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n",
    "\n",
    "    df_train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n",
    "    df_train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n",
    "\n",
    "    df_train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n",
    "    df_train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n",
    "\n",
    "    df_train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n",
    "    df_train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n",
    "\n",
    "    df_train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n",
    "    df_train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n",
    "\n",
    "    df_train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n",
    "    df_train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n",
    "\n",
    "    df_train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n",
    "    df_train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n",
    "\n",
    "    df_train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n",
    "    df_train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n",
    "\n",
    "    df_train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n",
    "    df_train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n",
    "\n",
    "    df_train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n",
    "    df_train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n",
    "\n",
    "    df_train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n",
    "    df_train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n",
    "\n",
    "    df_train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n",
    "    df_train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n",
    "\n",
    "    df_train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n",
    "    df_train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n",
    "\n",
    "    df_train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n",
    "    df_train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n",
    "\n",
    "    df_train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n",
    "    df_train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n",
    "\n",
    "    df_train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n",
    "    df_train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n",
    "\n",
    "    df_train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n",
    "    df_train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n",
    "\n",
    "    df_train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n",
    "    df_train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n",
    "\n",
    "    df_train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n",
    "    df_train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n",
    "\n",
    "    df_train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n",
    "    df_train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n",
    "\n",
    "    df_train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n",
    "    df_train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n",
    "\n",
    "    df_train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n",
    "    df_train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n",
    "\n",
    "    df_train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n",
    "    df_train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n",
    "\n",
    "    df_train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n",
    "    df_train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n",
    "\n",
    "    df_train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n",
    "    df_train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n",
    "\n",
    "    df_train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n",
    "    df_train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n",
    "\n",
    "    df_train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n",
    "    df_train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n",
    "\n",
    "    df_train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n",
    "    df_train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n",
    "\n",
    "    df_train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n",
    "    df_train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n",
    "\n",
    "    df_train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n",
    "    df_train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n",
    "\n",
    "    df_train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n",
    "    df_train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n",
    "\n",
    "    df_train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n",
    "    df_train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n",
    "\n",
    "    df_train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n",
    "    df_train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n",
    "\n",
    "    df_train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n",
    "    df_train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n",
    "\n",
    "    df_train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n",
    "    df_train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n",
    "\n",
    "    df_train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n",
    "    df_train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n",
    "\n",
    "    df_train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n",
    "    df_train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n",
    "\n",
    "    df_train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n",
    "    df_train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n",
    "\n",
    "    df_train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n",
    "    df_train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n",
    "\n",
    "    df_train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n",
    "    df_train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n",
    "\n",
    "    df_train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n",
    "    df_train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n",
    "\n",
    "    df_train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n",
    "    df_train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1651311801610,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ec3a7b5f",
    "outputId": "edd5d93b-311a-4892-c168-e829dcd9c976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8181\n",
       "0    4399\n",
       "2    1296\n",
       "3     287\n",
       "4      99\n",
       "5      27\n",
       "6       9\n",
       "7       1\n",
       "8       1\n",
       "Name: annotation_length, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['annotation_length'] = df_train['annotation'].map(lambda x: len(x))\n",
    "display(df_train['annotation_length'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_qUU5T3qV12"
   },
   "source": [
    "# Pseudo Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651311801610,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "U9OQPqaQqV12",
    "outputId": "0193293c-9dcd-4413-c2a9-c50c443afd09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>case_num</th>\n",
       "      <th>pn_num</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>annotation</th>\n",
       "      <th>location</th>\n",
       "      <th>feature_text</th>\n",
       "      <th>pn_history</th>\n",
       "      <th>annotation_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00041_000</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Family-history-of-MI-OR-Family-history-of-myoc...</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00041_001</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>[MOM HAS THYROID PROBLEMS]</td>\n",
       "      <td>[532 556]</td>\n",
       "      <td>Family-history-of-thyroid-disorder</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00041_002</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>[PRESSURE ON HER CHEST]</td>\n",
       "      <td>[263 284]</td>\n",
       "      <td>Chest-pressure</td>\n",
       "      <td>17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  case_num  pn_num  feature_num                  annotation   location                                       feature_text                                         pn_history  annotation_length\n",
       "13  00041_000         0      41            0                          []         []  Family-history-of-MI-OR-Family-history-of-myoc...  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  0\n",
       "14  00041_001         0      41            1  [MOM HAS THYROID PROBLEMS]  [532 556]                 Family-history-of-thyroid-disorder  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  1\n",
       "15  00041_002         0      41            2     [PRESSURE ON HER CHEST]  [263 284]                                     Chest-pressure  17 Y/O M CAME TO THE CLINIC C/O HEART POUNDING...                  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[13:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 20128,
     "status": "ok",
     "timestamp": 1651311821733,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "K34gY7O1qV12"
   },
   "outputs": [],
   "source": [
    "pl_train = pd.read_csv('./pl_train.csv')\n",
    "pl_train['location'] = pl_train['location'].fillna('[]')\n",
    "pl_train['location'] = pl_train['location'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6c6437f"
   },
   "source": [
    "# CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1651311822249,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ed511f87",
    "outputId": "ef8ab8db-b3e9-485c-a82b-78f26e0cf54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    3575\n",
       "1    3575\n",
       "2    3575\n",
       "3    3575\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "kf = GroupKFold(n_splits=config.n_folds)\n",
    "groups = df_train['pn_num'].to_numpy()\n",
    "df_train.loc[:, 'fold'] = -1\n",
    "for n, (train_index, val_index) in enumerate(kf.split(df_train, df_train['location'], groups)):\n",
    "    df_train.loc[val_index, 'fold'] = n\n",
    "display(df_train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651311822250,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "526e4ac9"
   },
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    display(df_train.groupby('fold').size())\n",
    "    df_train = df_train.sample(n=500, random_state=0).reset_index(drop=True)\n",
    "    display(df_train.groupby('fold').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11e2590f"
   },
   "source": [
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1651311822250,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "BR6m_itarTmJ"
   },
   "outputs": [],
   "source": [
    "# # The following is necessary if you want to use the fast tokenizer for deberta v2 or v3\n",
    "# import shutil\n",
    "# from pathlib import Path\n",
    "# import transformers\n",
    "\n",
    "# transformers_path = Path(transformers.__file__[:-12])\n",
    "\n",
    "# input_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n",
    "\n",
    "# convert_file = input_dir / \"convert_slow_tokenizer.py\"\n",
    "# conversion_path = transformers_path/convert_file.name\n",
    "\n",
    "# if conversion_path.exists():\n",
    "#     conversion_path.unlink()\n",
    "\n",
    "# shutil.copy(convert_file, transformers_path)\n",
    "# deberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n",
    "\n",
    "# for filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n",
    "#     if str(filename).startswith(\"deberta\"):\n",
    "#         filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n",
    "#     else:\n",
    "#         filepath = deberta_v2_path/filename\n",
    "#     if filepath.exists():\n",
    "#         filepath.unlink()\n",
    "\n",
    "#     shutil.copy(input_dir/filename, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "3dfd6ffec9b24babadfec07ae9b4d4f2",
      "46e47f4bb99a40d18aa19d5363d705d7",
      "c4b736fcb0e848aa9c4af1acd87fc245",
      "138066817ded4fa69b551f5f348d64d3",
      "51a576ced81f4db398a59c17ee4ed72a",
      "9e5730dbbedc453084d26fce77c8f11a",
      "c8cdc3e86a9a45dc9d793c3af5c2b200",
      "6575cc7a10f4437aa7d11fa7ceca4763",
      "67a2c064710d4776931e123353ae4d7c",
      "41f47ec442474719936603b59d907c65",
      "ab79ac7e7d4347d4b7f5532338e155fc",
      "5da8d5ce32994a09bf936227fa5edd12",
      "30b2afa7062b47fab7587476a6eca617",
      "1fd0b6fc0fae481991b0ab4503a0b755",
      "845a7583cf5c41cca875cb882249410d",
      "c171770408b142d5b1226b47d46d1f01",
      "bae1237788084a8d866042ed69d2293c",
      "5373c537d30f41aba39af4334ecf6f36",
      "ec6dd9f7b1e849bab372cb5df4b93531",
      "4f40caab4b1e4310935b17be7b5a4e93",
      "99a4d42eeb4a4bd999d74f88e20e13f6",
      "940111d655744355b867729c5edeabcf",
      "de995a2f649e4cef8c85187aeba4cd3b",
      "0da24853130543829a39f79ab1fadcd1",
      "fbb2db51a41c4a4686709c9f01e6955f",
      "f911ea9470da45c5883a305e92b9787e",
      "73ab2df54724494ba033d8b01b517392",
      "fbccff640fa3407bb8ae2a2c1f40afe2",
      "44aa0c7a57fc429aa7fa7faa7a0e9eaa",
      "800add5dca784b57af4947833d6a9eef",
      "6cb0890136fe43869dfa504840a6cdf8",
      "b696976706ad4bc2a969cb9e15a82eb7",
      "00adb1f99dc140b4a293e96d77485bbe",
      "68f2c6ede37445a09e0e3f9445cfd187",
      "3d51c94c20ad4c83bc27023439d60d91",
      "1b50897e46d74bf0977a0218c424f596",
      "869542edce0442c8898a0717f9ff4a85",
      "cec4f5657c3241eeb6d8ba7ec0efb5ef",
      "24cf07e1a7c443259917d487a83cb32b",
      "a674d7856b3646d4b58736cd6da06412",
      "4215a5ca45ce4d368cbf69610e39b499",
      "e308a1e284024d48bf2ec05ce08ac860",
      "fcbd2f47603a4a9fa5bdd7720992d5b2",
      "e4367b4d96424071be69a99e544b9727"
     ]
    },
    "executionInfo": {
     "elapsed": 5774,
     "status": "ok",
     "timestamp": 1651311828017,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "819ca57b",
    "outputId": "750eb3b3-6785-4cae-dd99-dac2a0a0277f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../output/exp093tokenizer/tokenizer_config.json',\n",
       " '../output/exp093tokenizer/special_tokens_map.json',\n",
       " '../output/exp093tokenizer/vocab.json',\n",
       " '../output/exp093tokenizer/merges.txt',\n",
       " '../output/exp093tokenizer/added_tokens.json',\n",
       " '../output/exp093tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# from transformers.models.deberta_v2 import DebertaV2TokenizerFast\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "\n",
    "# tokenizer = DebertaV2TokenizerFast.from_pretrained(config.tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    config.tokenizer,\n",
    "    trim_offsets=False\n",
    ")\n",
    "tokenizer.save_pretrained(config.output_dir+'tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18702,
     "status": "ok",
     "timestamp": 1651311846702,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "7d057ad3",
    "outputId": "df7ffb47-75d7-4880-9106-9e2277566073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pn_history max(lengths): 433\n",
      "feature_text max(lengths): 30\n",
      "max_len: 466\n"
     ]
    }
   ],
   "source": [
    "pn_history_lengths = []\n",
    "for text in patient_notes[\"pn_history\"].fillna(\"\").to_list():\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    pn_history_lengths.append(length)\n",
    "pn_history_max_len = max(pn_history_lengths)\n",
    "logger.info(f\"pn_history max(lengths): {pn_history_max_len}\")\n",
    "\n",
    "features_lengths = []\n",
    "for text in features[\"feature_text\"].fillna(\"\").to_list():\n",
    "    length = len(tokenizer(text, add_special_tokens=False)[\"input_ids\"])\n",
    "    features_lengths.append(length)\n",
    "feature_text_max_len = max(features_lengths)\n",
    "logger.info(f\"feature_text max(lengths): {feature_text_max_len}\")\n",
    "\n",
    "config.max_len = pn_history_max_len + feature_text_max_len + 3\n",
    "logger.info(f\"max_len: {config.max_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06f9f616"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1651311846703,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "1387f638"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer:PreTrainedTokenizer, \n",
    "        max_len:int,\n",
    "        feature_text_max_len:int, \n",
    "        pn_history_max_len:int, \n",
    "        df:DataFrame) -> None:\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.feature_text_max_len = feature_text_max_len\n",
    "        self.pn_history_max_len = pn_history_max_len\n",
    "        self.feature_texts = df['feature_text'].to_numpy()\n",
    "        self.pn_historys = df['pn_history'].to_numpy()\n",
    "        self.annotation_lengths = df['annotation_length'].to_numpy()\n",
    "        self.locations = df['location'].to_numpy()\n",
    "\n",
    "        \n",
    "    def prepare_input_with_fixed_position(self, pn_history:str, feature_text:str) -> dict:\n",
    "\n",
    "        pn_history_token = self.tokenizer(\n",
    "            pn_history, \n",
    "            add_special_tokens=True,\n",
    "            max_length=self.pn_history_max_len+2, \n",
    "            padding='max_length',\n",
    "            return_offsets_mapping=False)\n",
    "        \n",
    "        feature_text_token = self.tokenizer(\n",
    "            feature_text, \n",
    "            add_special_tokens=True,\n",
    "            max_length=self.feature_text_max_len+2, \n",
    "            padding='max_length',\n",
    "            return_offsets_mapping=False)\n",
    "        for k,v in feature_text_token.items():\n",
    "            feature_text_token[k] = v[1:]\n",
    "        \n",
    "\n",
    "        token = {\n",
    "            'input_ids': pn_history_token['input_ids']+feature_text_token['input_ids'],\n",
    "            'attention_mask': pn_history_token['attention_mask']+feature_text_token['attention_mask'],\n",
    "            # 'token_type_ids': pn_history_token['token_type_ids']+list(torch.ones_like(torch.tensor(feature_text_token['token_type_ids'], dtype=torch.long)))\n",
    "        }\n",
    "        for k, v in token.items():\n",
    "            token[k] = torch.tensor(v[:self.max_len], dtype=torch.long)\n",
    "        return token\n",
    "    \n",
    "    \n",
    "    def create_label(self, text:str, annotation_length:int, location_list:list) -> Tensor:\n",
    "        \n",
    "        encoded = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_offsets_mapping=True)\n",
    "        offset_mapping = encoded['offset_mapping']\n",
    "        ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n",
    "        label = np.zeros(len(offset_mapping))\n",
    "        label[ignore_idxes] = -1\n",
    "        if annotation_length != 0:\n",
    "            for location in location_list:\n",
    "                for loc in [s.split() for s in location.split(';')]:\n",
    "                    start_idx = -1\n",
    "                    end_idx = -1\n",
    "                    start, end = int(loc[0]), int(loc[1])\n",
    "                    for idx in range(len(offset_mapping)):\n",
    "                        if (start_idx == -1) & (start < offset_mapping[idx][0]):\n",
    "                            start_idx = idx - 1\n",
    "                        if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n",
    "                            end_idx = idx + 1\n",
    "                    if start_idx == -1:\n",
    "                        start_idx = end_idx\n",
    "                    if (start_idx != -1) & (end_idx != -1):\n",
    "                        label[start_idx:end_idx] = 1\n",
    "                        \n",
    "        return torch.tensor(label[:self.max_len], dtype=torch.float)\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, item:int) -> tuple:\n",
    "        \n",
    "        inputs = self.prepare_input_with_fixed_position(\n",
    "            self.pn_historys[item],\n",
    "            self.feature_texts[item])\n",
    "        label = self.create_label(\n",
    "            self.pn_historys[item], \n",
    "            self.annotation_lengths[item], \n",
    "            self.locations[item])\n",
    "        \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "006c4b6c"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 430,
     "status": "ok",
     "timestamp": 1651311847113,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "aab0ac97"
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.optim import Optimizer\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "\n",
    "\n",
    "class CustomModel(Module):\n",
    "    \n",
    "    def __init__(self, model_name:str, config_path:str=None, pretrained:bool=False) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(\n",
    "                model_name, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = torch.nn.DataParallel(AutoModel.from_pretrained(\n",
    "                config.model, config=self.config))\n",
    "        else:\n",
    "            self.model = torch.nn.DataParallel(AutoModel(self.config))\n",
    "        self.initializer_range = 0.1\n",
    "        self.fc = torch.nn.DataParallel(nn.Linear(self.config.hidden_size, 1))\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "        \n",
    "    def _init_weights(self, module:Module) -> None:\n",
    "        \n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "        \n",
    "    def feature(self, inputs:Tensor) -> Tensor:\n",
    "        \n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        \n",
    "        return last_hidden_states\n",
    "\n",
    "    \n",
    "    def forward(self, inputs:Tensor) -> Tensor:\n",
    "        \n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "    \n",
    "class AWP:\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model:Module,\n",
    "        criterion:_Loss,\n",
    "        optimizer:Optimizer,\n",
    "        adv_param:str=\"weight\",\n",
    "        adv_lr:int=1,\n",
    "        adv_eps:float=0.2,\n",
    "        start_epoch:int=0,\n",
    "        adv_step:int=1,\n",
    "        scaler=None) -> None:\n",
    "        \n",
    "        self.model = model\n",
    "        self.criterion=criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.adv_param = adv_param\n",
    "        self.adv_lr = adv_lr\n",
    "        self.adv_eps = adv_eps\n",
    "        self.start_epoch = start_epoch\n",
    "        self.adv_step = adv_step\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}\n",
    "        self.scaler = scaler\n",
    "\n",
    "        \n",
    "    def attack_backward(self, inputs:Tensor, labels:Tensor, epoch:int) -> None:\n",
    "        \n",
    "        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n",
    "            return None\n",
    "        self._save() \n",
    "        for i in range(self.adv_step):\n",
    "            self._attack_step() \n",
    "            with torch.cuda.amp.autocast():\n",
    "                y_preds = self.model(inputs)\n",
    "                adv_loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "                adv_loss = torch.masked_select(adv_loss, labels.view(-1, 1) != -1).mean()\n",
    "                adv_loss = adv_loss.mean()\n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(adv_loss).backward()\n",
    "        self._restore()\n",
    "\n",
    "        \n",
    "    def _attack_step(self) -> None:\n",
    "        e = 1e-6\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                norm1 = torch.norm(param.grad)\n",
    "                norm2 = torch.norm(param.data.detach())\n",
    "                if norm1 != 0 and not torch.isnan(norm1):\n",
    "                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n",
    "                    param.data.add_(r_at)\n",
    "                    param.data = torch.min(\n",
    "                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1])\n",
    "\n",
    "    def _save(self) -> None:\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None and self.adv_param in name:\n",
    "                if name not in self.backup:\n",
    "                    self.backup[name] = param.data.clone()\n",
    "                    grad_eps = self.adv_eps * param.abs().detach()\n",
    "                    self.backup_eps[name] = (\n",
    "                        self.backup[name] - grad_eps,\n",
    "                        self.backup[name] + grad_eps)\n",
    "\n",
    "                    \n",
    "    def _restore(self) -> None:\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.backup:\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}\n",
    "        self.backup_eps = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "250ef911"
   },
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651311847114,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "716ccfc0"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from math import floor\n",
    "from torch import inference_mode\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.reset()\n",
    "\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        \n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "        \n",
    "    def update(self, val:float, n=1) -> None:\n",
    "        \n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s) -> str:\n",
    "    \n",
    "    m = floor(s / 60)\n",
    "    s -= m * 60\n",
    "    \n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent) -> str:\n",
    "    \n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    \n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3139cba-ebd0-4faf-bb86-de5f7f032293"
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1651311847729,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "ef0f8033"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from logging import Logger\n",
    "import joblib\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer, AdamW\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch import cuda\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from wandb.sdk.wandb_config import Config\n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer_params(\n",
    "    model:Module, \n",
    "    encoder_lr:float, \n",
    "    decoder_lr:float, \n",
    "    weight_decay:float=0.0) -> list:\n",
    "\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "        'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    \n",
    "    return optimizer_parameters\n",
    "\n",
    "\n",
    "def get_scheduler(\n",
    "    scheduler:str, \n",
    "    optimizer:Optimizer, \n",
    "    num_warmup_steps:int, \n",
    "    num_train_steps:int, \n",
    "    num_cycles:int) -> _LRScheduler:\n",
    "    \n",
    "    if scheduler=='linear':\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=num_warmup_steps, \n",
    "            num_training_steps=num_train_steps\n",
    "        )\n",
    "    elif scheduler=='cosine':\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=num_warmup_steps, \n",
    "            num_training_steps=num_train_steps, \n",
    "            num_cycles=num_cycles\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Invalid Scheduler Name.')\n",
    "        \n",
    "    return scheduler\n",
    "\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, config:Config, tokenizer:PreTrainedTokenizer, logger:Logger) -> None:\n",
    "\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        self.logger = logger\n",
    "        self.device = torch.device('cuda' if cuda.is_available() else 'cpu')\n",
    "        \n",
    "        \n",
    "    def log(self, data:dict, prefix:str='') -> None:\n",
    "        \n",
    "        min_str_length = min([len(k) for k in data.keys()])\n",
    "        n_same_char_seqs = 0\n",
    "        for i in range(min_str_length):\n",
    "            s = set([k[i] for k in data.keys()])\n",
    "            if len(s)==1:\n",
    "                n_same_char_seqs+=1\n",
    "            else:\n",
    "                break\n",
    "        str_logs = [f'{k}: {v}' for k,v in data.items()]\n",
    "        s = ' '.join(\n",
    "            [l[n_same_char_seqs:].capitalize() for l in str_logs])\n",
    "        if prefix != '':\n",
    "            s = f'{prefix} - {s}'\n",
    "        self.logger.info(s)\n",
    "        wandb.log(data)\n",
    "        \n",
    "        \n",
    "    def compute_loss(self, y_preds:Tensor, labels:Tensor, batch_size:int, loss_th:float) -> tuple:\n",
    "       \n",
    "        loss = self.criterion(y_preds.squeeze(-1), labels.squeeze(-1))\n",
    "        samplewise_losses = []\n",
    "        for i in range(batch_size):\n",
    "            samplewise_losses.append(\n",
    "                torch.masked_select(loss[i], labels[i].squeeze(-1) != -1).mean()\n",
    "            )\n",
    "        loss = torch.stack(samplewise_losses)\n",
    "        loss_filter = torch.ones(batch_size, device=self.device)\n",
    "        if loss_th is not None:\n",
    "            mask = loss > loss_th\n",
    "            n_masked = mask.sum()\n",
    "            if n_masked > 0:\n",
    "                self.logger.info(f\"{n_masked} sample's loss was removed.\")\n",
    "            loss_filter[mask] = 0.0\n",
    "        else:\n",
    "            n_masked=0\n",
    "            \n",
    "        samplewise_losses = []\n",
    "        if loss_th is None:\n",
    "            for l in samplewise_losses:\n",
    "                samplewise_losses.append(l.item())\n",
    "                \n",
    "        return (loss*loss_filter).sum()/(batch_size-n_masked), samplewise_losses\n",
    "\n",
    "        \n",
    "    def train_with_eval(\n",
    "        self, \n",
    "        model:Module, \n",
    "        fold:int, \n",
    "        dls:tuple, \n",
    "        optimizer:Optimizer, \n",
    "        epoch:int, \n",
    "        scheduler:_LRScheduler, \n",
    "        loss_th:float, \n",
    "        valid_texts:list, \n",
    "        valid_labels:ndarray,\n",
    "        n_vl:int,\n",
    "        best_score:float) -> tuple:\n",
    "        \n",
    "        tr_dl, vl_dl = dls\n",
    "        model.train()\n",
    "        scaler = cuda.amp.GradScaler(enabled=self.config.apex)\n",
    "        awp = AWP(\n",
    "            model,\n",
    "            self.criterion,\n",
    "            optimizer,\n",
    "            adv_lr=self.config.adv_lr,\n",
    "            adv_eps=self.config.adv_eps,\n",
    "            start_epoch=self.config.adv_start_epoch,\n",
    "            scaler=scaler)\n",
    "        \n",
    "        am = AverageMeter()\n",
    "        samplewise_losses = []\n",
    "        start = end = time.time()\n",
    "        global_step = 0\n",
    "        for step, (inputs, labels) in enumerate(tr_dl):\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            batch_size = labels.size(0)\n",
    "            with cuda.amp.autocast(enabled=self.config.apex):\n",
    "                y_preds = model(inputs)\n",
    "                \n",
    "            loss, sl = self.compute_loss(\n",
    "                y_preds=y_preds, \n",
    "                labels=labels, \n",
    "                batch_size=batch_size, \n",
    "                loss_th=loss_th)\n",
    "            samplewise_losses += sl\n",
    "            if self.config.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.config.gradient_accumulation_steps\n",
    "            am.update(loss.item(), batch_size)            \n",
    "            scaler.scale(loss).backward()\n",
    "            awp.attack_backward(inputs, labels, epoch)\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                model.parameters(), self.config.max_grad_norm)\n",
    "            if (step + 1) % self.config.gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                if self.config.batch_scheduler:\n",
    "                    scheduler.step()\n",
    "            if step % self.config.print_freq == 0 or step == (len(tr_dl)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                    'Elapsed {remain:s} '\n",
    "                    'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                    'Grad: {grad_norm:.4f}  '\n",
    "                    'LR: {lr:.8f}  '\n",
    "                    .format(epoch+1, step, len(tr_dl), \n",
    "                            remain=timeSince(start, float(step+1)/len(tr_dl)),\n",
    "                            loss=am,\n",
    "                            grad_norm=grad_norm,\n",
    "                            lr=scheduler.get_lr()[0]))\n",
    "            wandb.log({f\"[fold{fold}] loss\": am.val,\n",
    "                    f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "            \n",
    "            if (step + 1) % self.config.n_eval_steps == 0:\n",
    "                model.eval()\n",
    "                avg_vl_loss, predictions = self.infer(\n",
    "                    model, vl_dl, n_vl)\n",
    "                score, best_th = self.evaluate(\n",
    "                    predictions=predictions,\n",
    "                    valid_texts=valid_texts, \n",
    "                    valid_labels=valid_labels,\n",
    "                    th_range=self.config.th_range, \n",
    "                    th_step=self.config.th_step)\n",
    "                self.log({\n",
    "                    f'[fold{fold}] epoch': epoch+1,\n",
    "                    f'[fold{fold}] step': step,\n",
    "                    f'[fold{fold}] avg_val_loss': avg_vl_loss,\n",
    "                    f'[fold{fold}] score': score,\n",
    "                    f'[fold{fold}] best_th': best_th\n",
    "                })\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    self.save_ckpt(\n",
    "                        fold=fold, \n",
    "                        model=model, \n",
    "                        predictions=predictions)\n",
    "                model.train()\n",
    "                \n",
    "        return am.avg, best_score, samplewise_losses\n",
    "\n",
    "    \n",
    "    @inference_mode()\n",
    "    def infer(self, model:Module, vl_dl:DataLoader, n_vl:int) -> tuple:\n",
    "        \n",
    "        model.eval()\n",
    "        losses = AverageMeter()\n",
    "        preds = []\n",
    "        for inputs, labels in vl_dl:\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            batch_size = labels.size(0)\n",
    "            y_preds = model(inputs)\n",
    "            loss = self.criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "            loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "            if self.config.gradient_accumulation_steps > 1:\n",
    "                loss = loss / self.config.gradient_accumulation_steps\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        predictions = np.concatenate(preds).reshape(\n",
    "            (n_vl, self.config.max_len)\n",
    "        )\n",
    "        \n",
    "        return losses.avg, predictions\n",
    "\n",
    "    \n",
    "    def create_dl(self, df:DataFrame, feature_text_max_len:int, pn_history_max_len:int, is_train:bool, seed:int) -> DataLoader:\n",
    "        \n",
    "        ds = TrainDataset(\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_len=self.config.max_len,\n",
    "            feature_text_max_len=feature_text_max_len,\n",
    "            pn_history_max_len=pn_history_max_len,\n",
    "            df=df)\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed+int(is_train))\n",
    "        \n",
    "        return DataLoader(\n",
    "            ds,\n",
    "            batch_size=self.config.batch_size if is_train else self.config.batch_size * 2,\n",
    "            shuffle=is_train,\n",
    "            num_workers=self.config.num_workers,\n",
    "            pin_memory=True, \n",
    "            drop_last=is_train,\n",
    "            generator=g\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def evaluate(self, predictions:ndarray, valid_texts:tuple, valid_labels:ndarray, th_range:list, th_step:float=0.005) -> tuple:\n",
    "        \n",
    "        char_probs = get_char_probs(\n",
    "            valid_texts, \n",
    "            predictions, \n",
    "            self.tokenizer)\n",
    "        best_score=-100\n",
    "        for th in np.arange(th_range[0], th_range[1], th_step):\n",
    "            th = np.round(th,4)\n",
    "            results = get_results(\n",
    "                char_probs, \n",
    "                valid_texts, \n",
    "                th=th\n",
    "            )\n",
    "            preds = get_predictions(results)\n",
    "            score = get_score(valid_labels, preds)\n",
    "            if best_score < score:\n",
    "                best_th=th\n",
    "                best_score=score\n",
    "        return best_score, best_th\n",
    "    \n",
    "    \n",
    "    def save_ckpt(self, fold:int, model:Module, predictions:ndarray) -> None:\n",
    "        \n",
    "        torch.save(\n",
    "            {'model': model.state_dict(),'predictions': predictions},\n",
    "            f'{self.config.output_dir}{self.config.ckpt_name}_fold{fold}_best.pth'\n",
    "        )\n",
    "        self.logger.info('model has been saved.')\n",
    "\n",
    "        \n",
    "    def compute_loss_th(self, samplewise_losses:list, fold:int, epoch:int) -> float:\n",
    "\n",
    "        mu_loss = np.mean(samplewise_losses)\n",
    "        std_loss = np.std(samplewise_losses)\n",
    "        loss_th = mu_loss+std_loss*self.config.n_loss_removal_std\n",
    "        joblib.dump(\n",
    "            value=samplewise_losses, \n",
    "            filename=f'samplewise_losses_f{fold}_e{epoch}.pkl', \n",
    "            compress=3)\n",
    "        \n",
    "        return loss_th\n",
    "    \n",
    "    \n",
    "    def run(\n",
    "        self,\n",
    "        df:DataFrame,\n",
    "        pl_df:DataFrame,\n",
    "        feature_text_max_len:int, \n",
    "        pn_history_max_len:int) -> None:\n",
    "    \n",
    "        oof_df = pd.DataFrame()\n",
    "        for f in range(self.config.n_folds):\n",
    "            self.logger.info(f\"========== fold: {f} training ==========\")\n",
    "            \n",
    "            model = CustomModel(\n",
    "                model_name=self.config.model, \n",
    "                config_path=None, \n",
    "                pretrained=True).to(self.device)\n",
    "\n",
    "            tr_df = df[df['fold'] != f].reset_index(drop=True)\n",
    "            if self.config.pl_frac > 0.0:\n",
    "                tr_pl_df = pl_df.sample(frac=self.config.pl_frac, random_state=self.config.seed)\n",
    "                self.logger.info(f'{len(tr_pl_df)} pseudo labeled data was sampled.')\n",
    "                tr_df = pd.concat(\n",
    "                    (tr_df, tr_pl_df)\n",
    "                ).sample(frac=1.0, random_state=self.config.seed)\n",
    "            tr_dl = self.create_dl(\n",
    "                df=tr_df, \n",
    "                feature_text_max_len=feature_text_max_len, \n",
    "                pn_history_max_len=pn_history_max_len, \n",
    "                is_train=True,\n",
    "                seed=self.config.seed\n",
    "            )\n",
    "            num_train_steps = int(len(tr_df) / self.config.batch_size * self.config.epochs)\n",
    "            \n",
    "            vl_df = df[df['fold'] == f].reset_index(drop=True)\n",
    "            vl_dl = self.create_dl(\n",
    "                df=vl_df, \n",
    "                feature_text_max_len=feature_text_max_len, \n",
    "                pn_history_max_len=pn_history_max_len, \n",
    "                is_train=False,\n",
    "                seed=self.config.seed)\n",
    "            valid_texts = vl_df['pn_history'].to_numpy()\n",
    "            valid_labels = create_labels_for_scoring(vl_df)\n",
    "\n",
    "            optimizer_parameters = get_optimizer_params(\n",
    "                model,\n",
    "                encoder_lr=self.config.encoder_lr, \n",
    "                decoder_lr=self.config.decoder_lr,\n",
    "                weight_decay=self.config.weight_decay)\n",
    "            optimizer = AdamW(\n",
    "                optimizer_parameters, \n",
    "                lr=self.config.encoder_lr, \n",
    "                eps=self.config.eps, \n",
    "                betas=self.config.betas)\n",
    "            scheduler = get_scheduler(\n",
    "                scheduler=self.config.scheduler, \n",
    "                optimizer=optimizer, \n",
    "                num_warmup_steps=self.config.num_warmup_steps,\n",
    "                num_train_steps=num_train_steps,\n",
    "                num_cycles=self.config.num_cycles)\n",
    "            \n",
    "            best_score = 0\n",
    "            for epoch in range(self.config.epochs):\n",
    "\n",
    "                if epoch==self.config.loss_removal_start_ep:\n",
    "                    loss_th = self.compute_loss_th(\n",
    "                        samplewise_losses=samplewise_losses, \n",
    "                        fold=f, \n",
    "                        epoch=epoch)\n",
    "                    self.logger.info(f'Loss th: {loss_th}')\n",
    "                \n",
    "                avg_tr_loss, stepwise_best_score, samplewise_losses = self.train_with_eval(\n",
    "                    model,\n",
    "                    f, \n",
    "                    (tr_dl, vl_dl), \n",
    "                    optimizer, \n",
    "                    epoch, \n",
    "                    scheduler,\n",
    "                    loss_th if epoch>=self.config.loss_removal_start_ep else None,\n",
    "                    valid_texts,\n",
    "                    valid_labels,\n",
    "                    len(vl_df),\n",
    "                    best_score)\n",
    "                \n",
    "                avg_vl_loss, predictions = self.infer(\n",
    "                    model, vl_dl, len(vl_df))\n",
    "                score, best_th = self.evaluate(\n",
    "                    predictions=predictions,\n",
    "                    valid_texts=valid_texts, \n",
    "                    valid_labels=valid_labels,\n",
    "                    th_range=self.config.th_range, \n",
    "                    th_step=self.config.th_step)\n",
    "                \n",
    "                self.log({\n",
    "                    f\"[fold{f}] epoch\": epoch+1, \n",
    "                    f\"[fold{f}] avg_train_loss\": avg_tr_loss, \n",
    "                    f\"[fold{f}] avg_val_loss\": avg_vl_loss,\n",
    "                    f\"[fold{f}] score\": score,\n",
    "                    f\"[fold{f}] best_th\": best_th})\n",
    "                \n",
    "                if score > stepwise_best_score:\n",
    "                    best_score = score\n",
    "                    self.save_ckpt(\n",
    "                        fold=f, \n",
    "                        model=model, \n",
    "                        predictions=predictions)\n",
    "\n",
    "            predictions = torch.load(\n",
    "                f'{self.config.output_dir}{self.config.ckpt_name}_fold{f}_best.pth', \n",
    "                map_location=torch.device('cpu'))['predictions']\n",
    "            vl_df[[i for i in range(self.config.max_len)]] = predictions\n",
    "            oof_df = pd.concat([oof_df, vl_df])\n",
    "            \n",
    "            self.logger.info(f\"========== fold: {f} result ==========\")\n",
    "            \n",
    "            score, th = get_result(vl_df, self.tokenizer, self.config.max_len)\n",
    "            self.log({\n",
    "                f\"[fold{f}] overall score\": score,\n",
    "                f\"[fold{f}] overall best th\": th\n",
    "            })\n",
    "            oof_df.to_pickle(f'{self.config.output_dir}oof_df_fold{f}.pkl')\n",
    "        \n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        self.logger.info(f\"========== CV ==========\")\n",
    "        score, th = get_result(oof_df, self.tokenizer, self.config.max_len)\n",
    "        self.log({\n",
    "            f\"overall score\": score,\n",
    "            f\"overall best th\": th\n",
    "        })\n",
    "        oof_df.to_pickle(self.config.output_dir+'oof_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "executionInfo": {
     "elapsed": 226790,
     "status": "error",
     "timestamp": 1651312074514,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "db38bc60",
    "outputId": "17705e20-a2c2-4205-bb80-5f45fad323fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Some weights of the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "188067 pseudo labeled data was sampled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/8283] Elapsed 0m 5s (remain 822m 50s) Loss: 0.3341(0.3341) Grad: inf  LR: 0.00002500  \n",
      "Epoch: [1][1000/8283] Elapsed 6m 17s (remain 45m 46s) Loss: 0.0026(0.0132) Grad: 1715.9655  LR: 0.00002497  \n",
      "Epoch: [1][2000/8283] Elapsed 12m 27s (remain 39m 6s) Loss: 0.0061(0.0093) Grad: 2368.5081  LR: 0.00002490  \n",
      "Epoch: [1][3000/8283] Elapsed 18m 36s (remain 32m 45s) Loss: 0.0031(0.0077) Grad: 6045.9448  LR: 0.00002478  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][4000/8283] Elapsed 24m 46s (remain 26m 31s) Loss: 0.0047(0.0068) Grad: 6762.6646  LR: 0.00002460  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 4999 Avg_val_loss: 0.011750828100146948 Score: 0.9037064746407308 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5000/8283] Elapsed 31m 34s (remain 20m 43s) Loss: 0.0094(0.0062) Grad: 15460.6738  LR: 0.00002438  \n",
      "Epoch: [1][6000/8283] Elapsed 37m 45s (remain 14m 21s) Loss: 0.0034(0.0058) Grad: 10752.3838  LR: 0.00002411  \n",
      "Epoch: [1][7000/8283] Elapsed 43m 55s (remain 8m 2s) Loss: 0.0186(0.0054) Grad: 85314.6094  LR: 0.00002380  \n",
      "Epoch: [1][8000/8283] Elapsed 50m 5s (remain 1m 45s) Loss: 0.0043(0.0052) Grad: 18058.0469  LR: 0.00002344  \n",
      "Epoch: [1][8282/8283] Elapsed 51m 49s (remain 0m 0s) Loss: 0.0098(0.0051) Grad: 70320.9688  LR: 0.00002333  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Avg_train_loss: 0.005085458439865021 Avg_val_loss: 0.013190323154513652 Score: 0.9079122064558958 Best_th: 0.405\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/8283] Elapsed 0m 0s (remain 106m 58s) Loss: 0.0025(0.0025) Grad: 10139.5322  LR: 0.00002332  \n",
      "Epoch: [2][1000/8283] Elapsed 6m 10s (remain 44m 51s) Loss: 0.0007(0.0029) Grad: 4518.3560  LR: 0.00002291  \n",
      "Epoch: [2][2000/8283] Elapsed 12m 20s (remain 38m 45s) Loss: 0.0016(0.0029) Grad: 12848.5693  LR: 0.00002245  \n",
      "Epoch: [2][3000/8283] Elapsed 18m 30s (remain 32m 33s) Loss: 0.0012(0.0029) Grad: 8784.3525  LR: 0.00002195  \n",
      "Epoch: [2][4000/8283] Elapsed 24m 39s (remain 26m 22s) Loss: 0.0069(0.0029) Grad: 118792.0078  LR: 0.00002142  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "Epoch: 2 Step: 4999 Avg_val_loss: 0.012897617803899558 Score: 0.9141604848085767 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5000/8283] Elapsed 31m 35s (remain 20m 43s) Loss: 0.0010(0.0028) Grad: 12947.6309  LR: 0.00002085  \n",
      "Epoch: [2][6000/8283] Elapsed 37m 44s (remain 14m 21s) Loss: 0.0019(0.0027) Grad: 21338.3926  LR: 0.00002024  \n",
      "Epoch: [2][7000/8283] Elapsed 43m 54s (remain 8m 2s) Loss: 0.0023(0.0027) Grad: 12779.3838  LR: 0.00001961  \n",
      "Epoch: [2][8000/8283] Elapsed 50m 4s (remain 1m 45s) Loss: 0.0032(0.0027) Grad: 13791.4580  LR: 0.00001894  \n",
      "Epoch: [2][8282/8283] Elapsed 51m 49s (remain 0m 0s) Loss: 0.0019(0.0027) Grad: 17692.7754  LR: 0.00001875  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Avg_train_loss: 0.0027393227487046623 Avg_val_loss: 0.013210365587024838 Score: 0.9153128526905435 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/8283] Elapsed 0m 0s (remain 111m 12s) Loss: 0.0012(0.0012) Grad: 12092.6494  LR: 0.00001875  \n",
      "Epoch: [3][1000/8283] Elapsed 6m 10s (remain 44m 53s) Loss: 0.0043(0.0023) Grad: 12303.4639  LR: 0.00001805  \n",
      "Epoch: [3][2000/8283] Elapsed 12m 19s (remain 38m 40s) Loss: 0.0022(0.0023) Grad: 5144.8955  LR: 0.00001733  \n",
      "Epoch: [3][3000/8283] Elapsed 18m 28s (remain 32m 30s) Loss: 0.0097(0.0022) Grad: 140528.7500  LR: 0.00001660  \n",
      "Epoch: [3][4000/8283] Elapsed 24m 37s (remain 26m 21s) Loss: 0.0044(0.0022) Grad: 11395.0771  LR: 0.00001584  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Step: 4999 Avg_val_loss: 0.013097011576686706 Score: 0.9150828574103549 Best_th: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5000/8283] Elapsed 31m 22s (remain 20m 35s) Loss: 0.0017(0.0022) Grad: 6548.7236  LR: 0.00001507  \n",
      "Epoch: [3][6000/8283] Elapsed 37m 32s (remain 14m 16s) Loss: 0.0002(0.0022) Grad: 604.4666  LR: 0.00001430  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][7000/8283] Elapsed 43m 42s (remain 8m 0s) Loss: 0.0013(0.0022) Grad: 13326.5430  LR: 0.00001351  \n",
      "Epoch: [3][8000/8283] Elapsed 49m 52s (remain 1m 45s) Loss: 0.0016(0.0022) Grad: 7546.3262  LR: 0.00001272  \n",
      "Epoch: [3][8282/8283] Elapsed 51m 36s (remain 0m 0s) Loss: 0.0015(0.0022) Grad: 12465.8623  LR: 0.00001250  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Avg_train_loss: 0.0022309792584640216 Avg_val_loss: 0.012694783568434365 Score: 0.9178011123101187 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/8283] Elapsed 0m 0s (remain 109m 19s) Loss: 0.0006(0.0006) Grad: 4080.7559  LR: 0.00001250  \n",
      "Epoch: [4][1000/8283] Elapsed 6m 10s (remain 44m 55s) Loss: 0.0070(0.0017) Grad: 13309.0986  LR: 0.00001171  \n",
      "Epoch: [4][2000/8283] Elapsed 12m 20s (remain 38m 43s) Loss: 0.0023(0.0017) Grad: 56853.9062  LR: 0.00001092  \n",
      "Epoch: [4][3000/8283] Elapsed 18m 29s (remain 32m 33s) Loss: 0.0010(0.0017) Grad: 13833.6914  LR: 0.00001014  \n",
      "Epoch: [4][4000/8283] Elapsed 24m 39s (remain 26m 23s) Loss: 0.0011(0.0017) Grad: 90265.4688  LR: 0.00000937  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Step: 4999 Avg_val_loss: 0.014817584660034496 Score: 0.9203483279229143 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][5000/8283] Elapsed 31m 35s (remain 20m 44s) Loss: 0.0001(0.0017) Grad: 5894.0503  LR: 0.00000861  \n",
      "Epoch: [4][6000/8283] Elapsed 37m 46s (remain 14m 21s) Loss: 0.0030(0.0017) Grad: 107121.7188  LR: 0.00000787  \n",
      "Epoch: [4][7000/8283] Elapsed 43m 55s (remain 8m 2s) Loss: 0.0004(0.0017) Grad: 74586.8828  LR: 0.00000715  \n",
      "Epoch: [4][8000/8283] Elapsed 50m 6s (remain 1m 45s) Loss: 0.0050(0.0017) Grad: 33073.3867  LR: 0.00000644  \n",
      "Epoch: [4][8282/8283] Elapsed 51m 51s (remain 0m 0s) Loss: 0.0004(0.0017) Grad: 47392.9648  LR: 0.00000625  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Avg_train_loss: 0.0016542017213872836 Avg_val_loss: 0.0143519527118627 Score: 0.9220191040843215 Best_th: 0.405\n",
      "model has been saved.\n",
      "Loss th: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][0/8283] Elapsed 0m 0s (remain 111m 6s) Loss: 0.0012(0.0012) Grad: 14671.3545  LR: 0.00000625  \n",
      "Epoch: [5][1000/8283] Elapsed 6m 11s (remain 45m 0s) Loss: 0.0008(0.0015) Grad: 1345.9244  LR: 0.00000558  \n",
      "Epoch: [5][2000/8283] Elapsed 12m 21s (remain 38m 46s) Loss: 0.0075(0.0014) Grad: 130651.5156  LR: 0.00000493  \n",
      "Epoch: [5][3000/8283] Elapsed 18m 31s (remain 32m 35s) Loss: 0.0015(0.0014) Grad: 10250.7441  LR: 0.00000432  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][4000/8283] Elapsed 24m 41s (remain 26m 25s) Loss: 0.0012(0.0014) Grad: 9313.9189  LR: 0.00000374  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Step: 4999 Avg_val_loss: 0.014754181912207938 Score: 0.9216699145246271 Best_th: 0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][5000/8283] Elapsed 31m 26s (remain 20m 38s) Loss: 0.0009(0.0014) Grad: 16625.2285  LR: 0.00000319  \n",
      "Epoch: [5][6000/8283] Elapsed 37m 36s (remain 14m 18s) Loss: 0.0058(0.0014) Grad: 26327.2461  LR: 0.00000269  \n",
      "Epoch: [5][7000/8283] Elapsed 43m 46s (remain 8m 0s) Loss: 0.0007(0.0014) Grad: 50605.7852  LR: 0.00000222  \n",
      "Epoch: [5][8000/8283] Elapsed 49m 56s (remain 1m 45s) Loss: 0.0005(0.0014) Grad: 16312.3906  LR: 0.00000179  \n",
      "Epoch: [5][8282/8283] Elapsed 51m 40s (remain 0m 0s) Loss: 0.0000(0.0014) Grad: 219.1571  LR: 0.00000167  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Avg_train_loss: 0.0013812389834318545 Avg_val_loss: 0.014866009515325924 Score: 0.921317729545806 Best_th: 0.405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][0/8283] Elapsed 0m 0s (remain 110m 38s) Loss: 0.0001(0.0001) Grad: 863.8013  LR: 0.00000167  \n",
      "Epoch: [6][1000/8283] Elapsed 6m 10s (remain 44m 56s) Loss: 0.0006(0.0012) Grad: 7778.8032  LR: 0.00000130  \n",
      "Epoch: [6][2000/8283] Elapsed 12m 21s (remain 38m 47s) Loss: 0.0017(0.0012) Grad: 22888.3711  LR: 0.00000097  \n",
      "Epoch: [6][3000/8283] Elapsed 18m 31s (remain 32m 36s) Loss: 0.0000(0.0012) Grad: 2033.1393  LR: 0.00000069  \n",
      "Epoch: [6][4000/8283] Elapsed 24m 41s (remain 26m 25s) Loss: 0.0004(0.0012) Grad: 31071.3867  LR: 0.00000046  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Step: 4999 Avg_val_loss: 0.015261896567327992 Score: 0.9215696395940658 Best_th: 0.43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [6][5000/8283] Elapsed 31m 28s (remain 20m 39s) Loss: 0.0004(0.0012) Grad: 32275.2852  LR: 0.00000027  \n",
      "Epoch: [6][6000/8283] Elapsed 37m 39s (remain 14m 19s) Loss: 0.0000(0.0012) Grad: 2024.0601  LR: 0.00000013  \n",
      "Epoch: [6][7000/8283] Elapsed 43m 50s (remain 8m 1s) Loss: 0.0003(0.0012) Grad: 19701.3828  LR: 0.00000004  \n",
      "Epoch: [6][8000/8283] Elapsed 49m 59s (remain 1m 45s) Loss: 0.0035(0.0012) Grad: 57028.7031  LR: 0.00000000  \n",
      "Epoch: [6][8282/8283] Elapsed 51m 44s (remain 0m 0s) Loss: 0.0007(0.0012) Grad: 6178.4395  LR: 0.00000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Avg_train_loss: 0.0011971083422504833 Avg_val_loss: 0.015368426342631553 Score: 0.9217613747717825 Best_th: 0.415\n",
      "========== fold: 0 result ==========\n",
      "Score: 0.9221312316565072 Best th: 0.3\n",
      "========== fold: 1 training ==========\n",
      "Some weights of the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "188067 pseudo labeled data was sampled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/8283] Elapsed 0m 0s (remain 108m 1s) Loss: 0.5233(0.5233) Grad: inf  LR: 0.00002500  \n",
      "Epoch: [1][1000/8283] Elapsed 6m 10s (remain 44m 52s) Loss: 0.0024(0.0142) Grad: 893.1953  LR: 0.00002497  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][2000/8283] Elapsed 12m 20s (remain 38m 45s) Loss: 0.0040(0.0099) Grad: 2940.7104  LR: 0.00002490  \n",
      "Epoch: [1][3000/8283] Elapsed 18m 30s (remain 32m 33s) Loss: 0.0103(0.0081) Grad: 7887.0459  LR: 0.00002478  \n",
      "Epoch: [1][4000/8283] Elapsed 24m 39s (remain 26m 23s) Loss: 0.0049(0.0071) Grad: 4326.8892  LR: 0.00002460  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Step: 4999 Avg_val_loss: 0.013500344244098956 Score: 0.8987133498891171 Best_th: 0.405\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][5000/8283] Elapsed 31m 26s (remain 20m 38s) Loss: 0.0026(0.0065) Grad: 3520.5713  LR: 0.00002438  \n",
      "Epoch: [1][6000/8283] Elapsed 37m 36s (remain 14m 18s) Loss: 0.0043(0.0061) Grad: 3191.6509  LR: 0.00002411  \n",
      "Epoch: [1][7000/8283] Elapsed 43m 46s (remain 8m 1s) Loss: 0.0077(0.0057) Grad: 16541.8086  LR: 0.00002380  \n",
      "Epoch: [1][8000/8283] Elapsed 49m 58s (remain 1m 45s) Loss: 0.0040(0.0055) Grad: 6139.5640  LR: 0.00002344  \n",
      "Epoch: [1][8282/8283] Elapsed 51m 43s (remain 0m 0s) Loss: 0.0068(0.0054) Grad: 19260.6504  LR: 0.00002333  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Avg_train_loss: 0.005389818153405408 Avg_val_loss: 0.012757261865674616 Score: 0.9038595760195843 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/8283] Elapsed 0m 0s (remain 115m 39s) Loss: 0.0027(0.0027) Grad: 6644.0498  LR: 0.00002332  \n",
      "Epoch: [2][1000/8283] Elapsed 6m 10s (remain 44m 58s) Loss: 0.0003(0.0025) Grad: 2268.1152  LR: 0.00002291  \n",
      "Epoch: [2][2000/8283] Elapsed 12m 20s (remain 38m 45s) Loss: 0.0095(0.0026) Grad: 4166.8818  LR: 0.00002245  \n",
      "Epoch: [2][3000/8283] Elapsed 18m 31s (remain 32m 35s) Loss: 0.0011(0.0027) Grad: 1626.2734  LR: 0.00002195  \n",
      "Epoch: [2][4000/8283] Elapsed 24m 40s (remain 26m 24s) Loss: 0.0034(0.0027) Grad: 17480.3672  LR: 0.00002142  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Step: 4999 Avg_val_loss: 0.013705867155865355 Score: 0.9097742038446094 Best_th: 0.46\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][5000/8283] Elapsed 31m 37s (remain 20m 45s) Loss: 0.0010(0.0027) Grad: 4935.4302  LR: 0.00002085  \n",
      "Epoch: [2][6000/8283] Elapsed 37m 48s (remain 14m 22s) Loss: 0.0022(0.0026) Grad: 20392.7910  LR: 0.00002024  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][7000/8283] Elapsed 43m 58s (remain 8m 3s) Loss: 0.0009(0.0026) Grad: 8325.9277  LR: 0.00001961  \n",
      "Epoch: [2][8000/8283] Elapsed 50m 8s (remain 1m 46s) Loss: 0.0021(0.0026) Grad: 35387.3828  LR: 0.00001894  \n",
      "Epoch: [2][8282/8283] Elapsed 51m 53s (remain 0m 0s) Loss: 0.0001(0.0026) Grad: 3217.8853  LR: 0.00001875  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Avg_train_loss: 0.002573064137299282 Avg_val_loss: 0.013340725484401822 Score: 0.9129785151218508 Best_th: 0.53\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/8283] Elapsed 0m 0s (remain 115m 45s) Loss: 0.0019(0.0019) Grad: 8963.7598  LR: 0.00001875  \n",
      "Epoch: [3][1000/8283] Elapsed 6m 10s (remain 44m 57s) Loss: 0.0038(0.0021) Grad: 8410.0977  LR: 0.00001805  \n",
      "Epoch: [3][2000/8283] Elapsed 12m 20s (remain 38m 45s) Loss: 0.0026(0.0021) Grad: 9232.8027  LR: 0.00001733  \n",
      "Epoch: [3][3000/8283] Elapsed 18m 30s (remain 32m 34s) Loss: 0.0017(0.0021) Grad: 11513.2900  LR: 0.00001660  \n",
      "Epoch: [3][4000/8283] Elapsed 24m 40s (remain 26m 24s) Loss: 0.0034(0.0021) Grad: 25858.2852  LR: 0.00001584  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Step: 4999 Avg_val_loss: 0.014555751046986429 Score: 0.914620367970977 Best_th: 0.45\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][5000/8283] Elapsed 31m 38s (remain 20m 46s) Loss: 0.0033(0.0020) Grad: 19163.3047  LR: 0.00001507  \n",
      "Epoch: [3][6000/8283] Elapsed 37m 48s (remain 14m 22s) Loss: 0.0002(0.0020) Grad: 4867.2388  LR: 0.00001430  \n",
      "Epoch: [3][7000/8283] Elapsed 43m 59s (remain 8m 3s) Loss: 0.0016(0.0020) Grad: 46693.5312  LR: 0.00001351  \n",
      "Epoch: [3][8000/8283] Elapsed 50m 9s (remain 1m 46s) Loss: 0.0017(0.0020) Grad: 11218.2617  LR: 0.00001272  \n",
      "Epoch: [3][8282/8283] Elapsed 51m 53s (remain 0m 0s) Loss: 0.0008(0.0020) Grad: 6701.2935  LR: 0.00001250  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Avg_train_loss: 0.0020098665964634384 Avg_val_loss: 0.014554341828671994 Score: 0.9172815614360079 Best_th: 0.4\n",
      "model has been saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][0/8283] Elapsed 0m 0s (remain 115m 13s) Loss: 0.0003(0.0003) Grad: 2140.3879  LR: 0.00001250  \n",
      "Epoch: [4][1000/8283] Elapsed 6m 11s (remain 45m 3s) Loss: 0.0015(0.0016) Grad: 12474.3613  LR: 0.00001171  \n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,\n",
    "    logger=logger)\n",
    "\n",
    "trainer.run(\n",
    "    df=df_train,\n",
    "    pl_df=pl_train,\n",
    "    feature_text_max_len=feature_text_max_len, \n",
    "    pn_history_max_len=pn_history_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "aborted",
     "timestamp": 1651312074512,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f5a96081-3aa7-4948-be95-67e31d3bd7e6"
   },
   "outputs": [],
   "source": [
    "commit_msg = '\"run_name: ' + wandb.run.name[:wandb.run.name.rfind('-')] + '\"'\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1651312074513,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "a8ac591e"
   },
   "outputs": [],
   "source": [
    "# !git add baseline-train.ipynb\n",
    "# !git add ../input/raiii-nbme/config.yml\n",
    "# !git commit -m $commit_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "aborted",
     "timestamp": 1651312074513,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "f9EURHdaqV15"
   },
   "outputs": [],
   "source": [
    "12.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1651312074514,
     "user": {
      "displayName": "青田雅輝",
      "userId": "18222903918360710455"
     },
     "user_tz": -540
    },
    "id": "sFN1cCF8zcK4"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9392/1575908533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-self-supervised-learning-9epoch/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if cuda.is_available() else 'cpu')\n",
    "model = CustomModel(\n",
    "    model_name=config.model,\n",
    "    config_path=None, \n",
    "    pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.config, \"../output/config.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"../input/roberta-large-self-supervised-learning-9epoch/\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.18.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "baseline-train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00adb1f99dc140b4a293e96d77485bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0da24853130543829a39f79ab1fadcd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbccff640fa3407bb8ae2a2c1f40afe2",
      "placeholder": "​",
      "style": "IPY_MODEL_44aa0c7a57fc429aa7fa7faa7a0e9eaa",
      "value": "Downloading: 100%"
     }
    },
    "138066817ded4fa69b551f5f348d64d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41f47ec442474719936603b59d907c65",
      "placeholder": "​",
      "style": "IPY_MODEL_ab79ac7e7d4347d4b7f5532338e155fc",
      "value": " 482/482 [00:00&lt;00:00, 4.01kB/s]"
     }
    },
    "1b50897e46d74bf0977a0218c424f596": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4215a5ca45ce4d368cbf69610e39b499",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e308a1e284024d48bf2ec05ce08ac860",
      "value": 1355863
     }
    },
    "1fd0b6fc0fae481991b0ab4503a0b755": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec6dd9f7b1e849bab372cb5df4b93531",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f40caab4b1e4310935b17be7b5a4e93",
      "value": 898823
     }
    },
    "24cf07e1a7c443259917d487a83cb32b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30b2afa7062b47fab7587476a6eca617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bae1237788084a8d866042ed69d2293c",
      "placeholder": "​",
      "style": "IPY_MODEL_5373c537d30f41aba39af4334ecf6f36",
      "value": "Downloading: 100%"
     }
    },
    "3d51c94c20ad4c83bc27023439d60d91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24cf07e1a7c443259917d487a83cb32b",
      "placeholder": "​",
      "style": "IPY_MODEL_a674d7856b3646d4b58736cd6da06412",
      "value": "Downloading: 100%"
     }
    },
    "3dfd6ffec9b24babadfec07ae9b4d4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46e47f4bb99a40d18aa19d5363d705d7",
       "IPY_MODEL_c4b736fcb0e848aa9c4af1acd87fc245",
       "IPY_MODEL_138066817ded4fa69b551f5f348d64d3"
      ],
      "layout": "IPY_MODEL_51a576ced81f4db398a59c17ee4ed72a"
     }
    },
    "41f47ec442474719936603b59d907c65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4215a5ca45ce4d368cbf69610e39b499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44aa0c7a57fc429aa7fa7faa7a0e9eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "46e47f4bb99a40d18aa19d5363d705d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e5730dbbedc453084d26fce77c8f11a",
      "placeholder": "​",
      "style": "IPY_MODEL_c8cdc3e86a9a45dc9d793c3af5c2b200",
      "value": "Downloading: 100%"
     }
    },
    "4f40caab4b1e4310935b17be7b5a4e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "51a576ced81f4db398a59c17ee4ed72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5373c537d30f41aba39af4334ecf6f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5da8d5ce32994a09bf936227fa5edd12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_30b2afa7062b47fab7587476a6eca617",
       "IPY_MODEL_1fd0b6fc0fae481991b0ab4503a0b755",
       "IPY_MODEL_845a7583cf5c41cca875cb882249410d"
      ],
      "layout": "IPY_MODEL_c171770408b142d5b1226b47d46d1f01"
     }
    },
    "6575cc7a10f4437aa7d11fa7ceca4763": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67a2c064710d4776931e123353ae4d7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68f2c6ede37445a09e0e3f9445cfd187": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d51c94c20ad4c83bc27023439d60d91",
       "IPY_MODEL_1b50897e46d74bf0977a0218c424f596",
       "IPY_MODEL_869542edce0442c8898a0717f9ff4a85"
      ],
      "layout": "IPY_MODEL_cec4f5657c3241eeb6d8ba7ec0efb5ef"
     }
    },
    "6cb0890136fe43869dfa504840a6cdf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73ab2df54724494ba033d8b01b517392": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "800add5dca784b57af4947833d6a9eef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "845a7583cf5c41cca875cb882249410d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99a4d42eeb4a4bd999d74f88e20e13f6",
      "placeholder": "​",
      "style": "IPY_MODEL_940111d655744355b867729c5edeabcf",
      "value": " 878k/878k [00:00&lt;00:00, 2.68MB/s]"
     }
    },
    "869542edce0442c8898a0717f9ff4a85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcbd2f47603a4a9fa5bdd7720992d5b2",
      "placeholder": "​",
      "style": "IPY_MODEL_e4367b4d96424071be69a99e544b9727",
      "value": " 1.29M/1.29M [00:00&lt;00:00, 1.88MB/s]"
     }
    },
    "940111d655744355b867729c5edeabcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99a4d42eeb4a4bd999d74f88e20e13f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e5730dbbedc453084d26fce77c8f11a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a674d7856b3646d4b58736cd6da06412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab79ac7e7d4347d4b7f5532338e155fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b696976706ad4bc2a969cb9e15a82eb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bae1237788084a8d866042ed69d2293c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c171770408b142d5b1226b47d46d1f01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b736fcb0e848aa9c4af1acd87fc245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6575cc7a10f4437aa7d11fa7ceca4763",
      "max": 482,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67a2c064710d4776931e123353ae4d7c",
      "value": 482
     }
    },
    "c8cdc3e86a9a45dc9d793c3af5c2b200": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cec4f5657c3241eeb6d8ba7ec0efb5ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de995a2f649e4cef8c85187aeba4cd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0da24853130543829a39f79ab1fadcd1",
       "IPY_MODEL_fbb2db51a41c4a4686709c9f01e6955f",
       "IPY_MODEL_f911ea9470da45c5883a305e92b9787e"
      ],
      "layout": "IPY_MODEL_73ab2df54724494ba033d8b01b517392"
     }
    },
    "e308a1e284024d48bf2ec05ce08ac860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4367b4d96424071be69a99e544b9727": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec6dd9f7b1e849bab372cb5df4b93531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f911ea9470da45c5883a305e92b9787e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b696976706ad4bc2a969cb9e15a82eb7",
      "placeholder": "​",
      "style": "IPY_MODEL_00adb1f99dc140b4a293e96d77485bbe",
      "value": " 446k/446k [00:00&lt;00:00, 719kB/s]"
     }
    },
    "fbb2db51a41c4a4686709c9f01e6955f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_800add5dca784b57af4947833d6a9eef",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6cb0890136fe43869dfa504840a6cdf8",
      "value": 456318
     }
    },
    "fbccff640fa3407bb8ae2a2c1f40afe2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcbd2f47603a4a9fa5bdd7720992d5b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
